{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c7e046-9bdf-48a1-9005-988a3f8ce243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# Go to the parent of the parent directory\n",
    "grandparent_dir = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "sys.path.append(grandparent_dir)\n",
    "\n",
    "# Now you can import your config\n",
    "from config import api_key\n",
    "\n",
    "client = OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e964eddb-de8d-46f2-b365-c7594820c1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ea74e6-1591-4ad8-bd87-d0e1e1718ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain.llms import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain.prompts import HumanMessagePromptTemplate, ChatPromptTemplate\n",
    "from langchain.document_loaders import CSVLoader\n",
    "\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import os"
   ]
  },
  {
   "cell_type": "raw",
   "id": "689e07d1-25ee-4678-aa57-e1df97ac0fb8",
   "metadata": {},
   "source": [
    "imports like `HumanMessage`, `SystemMessage`, `AIMessage` create prompt like \n",
    "\n",
    "```\n",
    "[{\"role\": \"syste\", \"content\" : \"you are bla bla bla\"},\n",
    " {\"role\": \"user\", \"content\" : content}]\n",
    "\n",
    "that we normally give directly to the openai API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca7ea35-fb5c-436b-b9cc-2e3763e3d0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14eaccf7-3a37-475a-83e4-e4cd6b2421f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(file_path=\"dataset.csv\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e82f33-83a1-4c56-8757-7387ea03d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].page_content.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4545bb8d-b536-451f-b8df-49926a37490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page_content(content):\n",
    "    fields = content.split(\"\\n\")\n",
    "    return {field.split(': ')[0]: field.split(\": \")[1] for field in fields if field}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34142339-f830-4d6d-915b-4a00d0ece7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data = [parse_page_content(document.page_content) for document in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f547ee02-bcc5-4b1f-b18c-2bfa5bdfcb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(parsed_data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8013a0-7d91-4b6d-b515-b84aabde3dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"Age\"]!=\"\"]\n",
    "average_age = df[\"Age\"].astype(float).mean()\n",
    "\n",
    "# most popular product category\n",
    "popular_category = df[\"Product Category\"].value_counts().idxmax()\n",
    "\n",
    "# gender distribution \n",
    "gender_distribution = df[\"Gender\"].value_counts()\n",
    "print(tabulate(gender_distribution.items(), headers=[\"Gender\",\"Count\"], tablefmt=\"grid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71fb84e-c569-4771-8898-a065836cb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "        [SystemMessage(content=(\"You are and expert data analysis assistent\")),\n",
    "         HumanMessagePromptTemplate.from_template(\n",
    "             \"\"\"\n",
    "             I have a dataset of customer purchaes with the following characteristics:\n",
    "             - Average age of customers {average_age}\n",
    "             - Gender distribution: {gender_distribution}\n",
    "\n",
    "             Based on this information, can you provide insights into the potential marketing strategies and product recommendation\n",
    "             \"\"\"\n",
    "         )\n",
    "        ])\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "output = llm.invoke(chat_template.format_messages(average_age=average_age, gender_distribution=gender_distribution))\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0b843c-f51f-4255-b89f-119e7b975168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from IPython.display import display, Markdown\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a785f3-693a-43dc-9ab0-ceb380e91b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fe8400-b7e5-4868-840a-4142a66fffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv(\"dataset.csv\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV file: {e}\")\n",
    "    raise # Raise for furhter handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b0b059-164f-47a8-9f9c-ff21ad4fff03",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:100]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd69498e-9a89-452c-ae9d-ddcec98300b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "# Create an OpenAI chat LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=api_key)\n",
    "\n",
    "analysis_template = \"\"\"\n",
    "Analyze the following data and extract key insight\n",
    "Data:\n",
    "{content_data}\n",
    "\n",
    "Key insight:\n",
    "\"\"\"\n",
    "\n",
    "analysis_prompt_template = PromptTemplate(input_variables=[\"content_data\"], template=analysis_template)\n",
    "lmm_chain = analysis_prompt_template | llm | StrOutputParser()\n",
    "\n",
    "response = lmm_chain.invoke({\"content_data\": data})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5bdaa8-7126-4bc5-8b2a-5600e960cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_template = \"\"\"\n",
    "Generate a report based on these key insights\n",
    "\n",
    "Key Insights: {insights} \n",
    "\n",
    "Summary: report\"\"\"\n",
    "summary_prompt_template = PromptTemplate(\n",
    "    input_variables=['insights'], \n",
    "    template=summary_template)\n",
    "\n",
    "seq_chain = ({\"insights\": analysis_prompt_template | llm | StrOutputParser()}\n",
    "             | summary_prompt_template\n",
    "             | llm\n",
    "             | StrOutputParser())\n",
    "\n",
    "print(seq_chain.invoke({\"content_data\": data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a928e1f-e9a5-456d-bc5b-d53292c43432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d654bf8e-3f6e-4e92-91a9-3d576a9483e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56df43d0-5928-40c2-bc11-f80971e97092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
