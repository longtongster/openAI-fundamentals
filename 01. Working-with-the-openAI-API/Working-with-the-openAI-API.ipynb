{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bf2148f-c116-4a47-b324-d82f02033845",
   "metadata": {},
   "source": [
    "# Working with the openAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c61e74-1735-4938-8906-11c78a991f11",
   "metadata": {},
   "source": [
    "If the snippet below runs without errors, you are good to go!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3229558-fab1-4ea6-babc-3253d3eb87be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import api_key\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec1922-ca93-4e7b-9841-12f7bd32e8e7",
   "metadata": {},
   "source": [
    "## Chapter 1 - Introduction to the OpenAI API\n",
    "\n",
    "### Section 1.1 What is the OpenAI API?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18271e92",
   "metadata": {},
   "source": [
    "#### Your first OpenAI API request!\n",
    "\n",
    "To preview what’s ahead, the Python code for sending a request to the OpenAI API is ready for you.\n",
    "\n",
    "Pass any question or instruction to the content argument and see how OpenAI's model responds!\n",
    "\n",
    "Here are a few prompts to try if you're struggling for ideas:\n",
    "\n",
    "- Why is learning the OpenAI API valuable for developers?\n",
    "- Suggest three tasks I could automate with the OpenAI API in my job.\n",
    "- In two sentences, how can the OpenAI API be used to upskill myself?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5356231e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    max_tokens=100,\n",
    "    # Enter your prompt\n",
    "    messages=[{\"role\": \"user\", \n",
    "               \"content\": \"Why is learning the OpenAI API valuable for developers?\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fceeeb4",
   "metadata": {},
   "source": [
    "### Section 1.2 - Making request to the OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64f5eee",
   "metadata": {},
   "source": [
    "#### Building an OpenAI API request\n",
    "\n",
    "Throughout the course, you'll write Python code to interact with the OpenAI API. Entering your own API key is not necessary to create requests and complete the exercises in this course.\n",
    "\n",
    "The `OpenAI` class has already been imported for you from the `openai` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59898803-0057-4d57-95b9-5cb983923c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"Write a polite reply accepting an AI Engineer job offer.\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0e4dc4-d7e1-42f9-b46e-bad141d43fde",
   "metadata": {},
   "source": [
    "#### Specifying an OpenAI model\n",
    "OpenAI offers multiple models for different use cases. In this exercise, you'll specify the model and define the role to structure your API requests.\n",
    "\n",
    "The `OpenAI` class has already been imported for you from the `openai` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fecd35-8bb0-49de-b2db-c0de95507f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  # Specify the model\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    # Assign the correct role\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"Announce my new AI Engineer role on LinkedIn.\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a71806e-2a9c-4959-be1e-4fbbde4197ed",
   "metadata": {},
   "source": [
    "#### Digging into the response\n",
    "One key skill in working with APIs is extracting the right data from a structured response. Now, you'll practice retrieving the necessary text from an OpenAI API response.\n",
    "\n",
    "The OpenAI class has already been imported for you from the openai library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e406a78b-4c99-4f5c-a9ee-a243fe4a38bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": \"Quick productivity tip.\"}]\n",
    ")\n",
    "\n",
    "# Extract the content from the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2febb8d8-0eeb-4af8-99d1-4f0e2b977a6a",
   "metadata": {},
   "source": [
    "## Chapter 2 - OpentAI's Text and Chat Capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ed03fc-0357-4533-b5e0-185f1c7b9577",
   "metadata": {},
   "source": [
    "### Section 2.1 Generating and transforming text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2200b2f-c59a-4021-8bd8-2d23c21d28be",
   "metadata": {},
   "source": [
    "#### Find and replace\n",
    "Text completion models can be used for much more than answering questions. In this exercise, you'll explore the model's ability to transform a text prompt.\n",
    "\n",
    "Find-and-replace tools have been around for decades, but they are often limited to identifying and replacing exact words or phrases. You've been provided with a block of text discussing cars, and you'll use a completion model to update the text to discuss planes instead, updating the text appropriately.\n",
    "\n",
    "Warning: if you send many requests or use lots of tokens in a short period, you may hit your rate limit and see an openai.error.RateLimitError. If you see this error, please wait a minute for your quota to reset and you should be able to begin sending more requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37435991-0470-45c1-9ce5-bf26c6805fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "prompt=\"\"\"Replace car with plane and adjust phrase:\n",
    "A car is a vehicle that is typically powered by an internal combustion engine or an electric motor. It has four wheels, and is designed to carry passengers and/or cargo on roads or highways. Cars have become a ubiquitous part of modern society, and are used for a wide variety of purposes, such as commuting, travel, and transportation of goods. Cars are often associated with freedom, independence, and mobility.\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\",\n",
    "             \"content\": prompt}],\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "# Extract and print the response text\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb5621-88a4-4e94-8706-b97c47b2605d",
   "metadata": {},
   "source": [
    "#### Text summarization\n",
    "One really common use case for using OpenAI's models is summarizing text. This has a ton of applications in business settings, including summarizing reports into concise one-pagers or a handful of bullet points, or extracting the next steps and timelines for different stakeholders.\n",
    "\n",
    "In this exercise, you'll summarize a passage of text on financial investment into two concise bullet points using a text completion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d46a573-638b-4d5b-8570-117cfff9a3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "prompt=\"\"\"Summarize the following text into two concise bullet points:\n",
    "Investment refers to the act of committing money or capital to an enterprise \n",
    "with the expectation of obtaining an added income or profit in return. \n",
    "There are a variety of investment options available, including stocks, bonds, \n",
    "mutual funds, real estate, precious metals, and currencies. \n",
    "Making an investment decision requires careful analysis, assessment of risk, and evaluation of potential rewards. \n",
    "Good investments have the ability to produce high returns over the long term \n",
    "while minimizing risk. Diversification of investment portfolios reduces risk exposure. \n",
    "Investment can be a valuable tool for building wealth, generating income, and \n",
    "achieving financial security. \n",
    "It is important to be diligent and informed when investing to avoid losses.\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  max_tokens=400, temperature=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c8eceb-65ba-4a1f-95ad-4a9728397e4f",
   "metadata": {},
   "source": [
    "#### Content generation\n",
    "\n",
    "AI is playing a much greater role in content generation, from creating marketing content such as blog post titles to creating outreach email templates for sales teams.\n",
    "\n",
    "In this exercise, you'll harness AI through the Chat Completions endpoint to generate a catchy slogan for a new restaurant. Feel free to test out different prompts, such as varying the type of cuisine (e.g., Italian, Chinese) or the type of restaurant (e.g., fine-dining, fast-food), to see how the response changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ba1cd3-7ccc-41dd-b4b6-b7c59a8ada01",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": \"Create a slogan for a new restaurant where people eat naked\"}],\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909d3c24-d023-4530-918b-f750304d4c75",
   "metadata": {},
   "source": [
    "### Section 2.2 - Sentiment analysis and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6db181-2245-4bab-b348-6189b7a73686",
   "metadata": {},
   "source": [
    "#### Classifying text sentiment\n",
    "As well as answering questions, transforming text, and generating new text, OpenAI's models can also be used for classification tasks, such as categorization and sentiment classification. This sort of task requires not only knowledge of the words but also a deeper understanding of their meaning.\n",
    "\n",
    "In this exercise, you'll explore using Chat Completions models for sentiment classification using reviews from an online shoe store called Toe-Tally Comfortable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59df9056-b66a-42ee-b2bd-0e3d1e030789",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Define a multi-line prompt to classify sentiment\n",
    "prompt = \"\"\"Classify the following statements are negative, positive or neutral:\n",
    "1. Unbelievably good!\n",
    "2. Shoes fell apart on the second use.\n",
    "3. The shoes look nice, but they aren't very comfortable.\n",
    "4. Can't wait to show them off!\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af909379-c99b-4efa-a43f-c68ba47175ce",
   "metadata": {},
   "source": [
    "#### Categorizing companies\n",
    "In this exercise, you'll use a Chat Completions model to categorize different companies. At first, you won't specify the categories to see how the model categorizes them. Then, you'll specify the categories in the prompt to ensure they are categorized in a desirable and predictable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317bc532-76d1-4939-b326-1f986875216b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Define a prompt for the categorization\n",
    "prompt = \"categorize the following companies: Apple, Microsoft, Saudi Aramco, Alphabet, Amazon, Berkshire Hathaway, NVIDIA, Meta, Tesla, LVMH into one of the following classes: Tech, Energy, Luxury Goods or Investments\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  max_tokens=100,\n",
    "  temperature=0.5\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bda7a-69ee-4870-8c1b-c8d3c91e6227",
   "metadata": {},
   "source": [
    "## Section 2.3 - Chat completions with GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57965938-36d7-4079-a312-f7f22aff8ba5",
   "metadata": {},
   "source": [
    "#### Chat Completions roles\n",
    "\n",
    "The Chat Completions endpoint supports three different roles to shape the messages sent to the model:\n",
    "\n",
    "System: controls assistant's behavior\n",
    "User: instruct the assistant\n",
    "Assistant: response to user instruction\n",
    "In this exercise, you'll make a request to the Chat Completions endpoint, including a system messages, to answer the following question:\n",
    "\n",
    "What is the difference between a for loop and a while loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe2f1fa-b1b8-46bf-b7b2-fa239d740a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  max_tokens=150,\n",
    "  messages=[\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": \"You are a helpful data science tutor that gives clear and concise answers.\"},\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": \"What is the difference between a for loop and a while loop?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "# Extract the assistant's text response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca52d1-6834-4c57-8ee1-7b26eeaf6c92",
   "metadata": {},
   "source": [
    "#### Code explanation\n",
    "One of the most popular use cases for using OpenAI models is for explaining complex content, such as technical jargon and code. This is a task that data practitioners, software engineers, and many others must tackle in their day-to-day as they review and utilize code written by others.\n",
    "\n",
    "In this exercise, you'll use the OpenAI API to explain a block of Python code to understand what it is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d16513b-e967-40ba-90ca-8e12d4d5232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "instruction = \"\"\"Explain what this Python code does in one sentence:\n",
    "import numpy as np\n",
    "\n",
    "heights_dict = {\"Mark\": 1.76, \"Steve\": 1.88, \"Adnan\": 1.73}\n",
    "heights = heights_dict.values()\n",
    "print(np.mean(heights))\n",
    "\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\",\n",
    "    \"content\": \"you are a computer science teacher that explains matter in simple, clear and concise words\"},\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": instruction}\n",
    "  ],\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03015122-2b67-448f-adad-875eb92deb45",
   "metadata": {},
   "source": [
    "### Section 2.4 - Multi-turn chat completions with GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728d043-b709-408d-b978-599c420636e1",
   "metadata": {},
   "source": [
    "#### In-context learning\n",
    "For more complex use cases, the models lack the understanding or context of the problem to provide a suitable response from a prompt. In these cases, you need to provide examples to the model for it to learn from, so-called in-context learning.\n",
    "\n",
    "In this exercise, you'll improve on a Python programming tutor built on the OpenAI API by providing an example that the model can learn from.\n",
    "\n",
    "Here is an example of a user and assistant message you can use, but feel free to try out your own:\n",
    "\n",
    "- User → Explain what the min() Python function does.\n",
    "- Assistant → The min() function returns the smallest item from an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab92373-17b2-4efa-8dd8-6803bdd351f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "   model=\"gpt-4o-mini\",\n",
    "   # Add a user and assistant message for in-context learning\n",
    "   messages=[\n",
    "     {\"role\": \"system\", \"content\": \"You are a helpful Python programming tutor.\"},\n",
    "     {\"role\": \"user\", \"content\": \"Explain what the min() Python function does.\"},\n",
    "     {\"role\": \"assistant\", \"content\": \"The min() function returns the smallest item from an iterable.\"},\n",
    "     {\"role\": \"user\", \"content\": \"Explain what the type() function does.\"}\n",
    "   ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8786ae-6a49-493b-a462-da7379742f98",
   "metadata": {},
   "source": [
    "#### Creating an AI chatbot\n",
    "An online learning platform called Easy as Pi that specializes in teaching math skills has contracted you to help develop an AI tutor. You immediately see that you can build this feature on top of the OpenAI API, and start to design a simple proof-of-concept (POC) for the major stakeholders at the company. This POC will demonstrate the core functionality required to build the final feature and the power of the OpenAI's GPT models.\n",
    "\n",
    "Example system and user messages have been provided for you, but feel free to play around with these to change the model's behavior or design a completely different chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf1bf24-6624-4291-8c48-73afb496cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful math tutor.\"}]\n",
    "user_msgs = [\"Explain what pi is.\", \"Summarize this in two bullet points.\"]\n",
    "\n",
    "for q in user_msgs:\n",
    "    print(\"User: \", q)\n",
    "    \n",
    "    # Create a dictionary for the user message from q and append to messages\n",
    "    user_dict = {\"role\": \"user\", \"content\": q}\n",
    "    messages.append(user_dict)\n",
    "    \n",
    "    # Create the API request\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    \n",
    "    # Convert the assistant's message to a dict and append to messages\n",
    "    assistant_dict = {\"role\": \"assistant\", \"content\": response.choices[0].message.content}\n",
    "    messages.append(assistant_dict)\n",
    "    print(\"Assistant: \", response.choices[0].message.content, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe0ffe7-fc41-4f55-8c7f-38ae5530809d",
   "metadata": {},
   "source": [
    "## Chapter 3 - Going Beyond Text Completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2b3296-8811-4279-8d33-1ffec0b711be",
   "metadata": {},
   "source": [
    "### Section 3.1 - Text moderation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f9350-b00d-4df8-9f2e-3371ef93555b",
   "metadata": {},
   "source": [
    "#### Requesting moderation\n",
    "Aside from text and chat completion models, OpenAI provides models with other capabilities, including text moderation. OpenAI's text moderation model is designed for evaluating prompts and responses to determine if they violate OpenAI's usage policies, including inciting hate speech and promoting violence.\n",
    "\n",
    "In this exercise, you'll test out OpenAI's moderation functionality on a sentence that may have been flagged as containing violent content using traditional word detection algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e56a3a-0367-4675-a505-a8890679f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a request to the Moderation endpoint\n",
    "response = client.moderations.create(\n",
    "    model=\"text-moderation-latest\",\n",
    "    input=\"My favorite book is To Kill a Mockingbird.\"\n",
    ")\n",
    "\n",
    "# Print the category scores\n",
    "print(response.results[0].category_scores.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeb5fec-f991-4132-89e1-91292db5106a",
   "metadata": {},
   "source": [
    "### Section 3.2 - Speech-to-Text with Whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0380602e-f33f-41a5-8924-64adf5488477",
   "metadata": {},
   "source": [
    "#### Creating a podcast transcript\n",
    "The OpenAI API `Audio` endpoint provides access to the Whisper model, which can be used for speech-to-text transcription and translation. In this exercise, you'll create a transcript from a DataFramed podcast episode with OpenAI Developer, Logan Kilpatrick.\n",
    "\n",
    "If you'd like to hear more from Logan, check out the full ChatGPT and the OpenAI Developer Ecosystem podcast episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0a69e6-b62b-4b4c-87a4-3d6bb88a761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the openai-audio.mp3 file\n",
    "audio_file = open(\"datacamp-q2-roadmap-short.mp3\", \"rb\")\n",
    "\n",
    "# Create a transcript from the audio file\n",
    "response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
    "\n",
    "# Extract and print the first 256 characters of the transcript text\n",
    "print(response.text[:255])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b65e05-a28d-41c3-ac54-c63a7e195655",
   "metadata": {},
   "source": [
    "#### Transcribing a non-English language\n",
    "The Whisper model can not only transcribe English language, but also performs well on speech in many other languages.\n",
    "\n",
    "In this exercise, you’ll create a transcript from `audio.m4a`, which contains speech in Portuguese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556bd22b-2c5b-437a-8892-197fdb3014f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the audio.m4a file\n",
    "audio_file= open(\"Recording_dutch.m4a\", \"rb\")\n",
    "\n",
    "# Create a transcript from the audio file\n",
    "response = client.audio.transcriptions.create(\n",
    "    model='whisper-1',\n",
    "    file=audio_file\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee357ff-4352-47d8-8aa4-737595e8147a",
   "metadata": {},
   "source": [
    "### Section 3.3 - Speech Translation with Whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e366e8f-28ef-4d63-84e8-1015206d9158",
   "metadata": {},
   "source": [
    "#### Translating Dutch\n",
    "Whisper can not only transcribe audio into its native language but also supports translation capabilities for creating English transcriptions.\n",
    "\n",
    "In this exercise, you'll return to the Portuguese audio, but this time, you'll translate it into English!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4566a413-ac77-47fa-89c2-e151129d06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the audio.m4a file\n",
    "audio_file = open(\"Recording_dutch.m4a\", \"rb\")\n",
    "\n",
    "# Create a translation from the audio file\n",
    "response = client.audio.translations.create(model=\"whisper-1\", file=audio_file)\n",
    "\n",
    "# Extract and print the translated text\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97991587-65fe-4339-9814-f443e1388857",
   "metadata": {},
   "source": [
    "#### Translating with prompts\n",
    "The quality of Whisper's translation can vary depending on the language spoken, the audio quality, and the model's awareness of the subject matter. If you have any extra context about what is being spoken about, you can send it along with the audio to the model to give it a helping hand.\n",
    "\n",
    "You've been provided with an audio file, audio.wav; you're not sure what language is spoken in it, but you do know it relates to a recent World Bank report. Because you don't know how well the model will perform on this unknown language, you opt to send the model this extra context to steer it in the right direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6026874d-2ba6-430c-92f8-3f162ce1c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the audio.wav file\n",
    "audio_file = open(\"Recording_dutch.m4a\",'rb')\n",
    "\n",
    "# Write an appropriate prompt to help the model\n",
    "prompt = \"This is Sacha introducing himself and talking about ChatGPT and a testfile\"\n",
    "\n",
    "# Create a translation from the audio file\n",
    "response = client.audio.translations.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e6f90e-bb43-4f2b-a270-66e4e30a56ce",
   "metadata": {},
   "source": [
    "### Section 3.4 - Combining models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd1f227-08f5-4b21-9a96-f12f28e98b34",
   "metadata": {},
   "source": [
    "#### Identifying audio language\n",
    "You've learned that you're not only limited to creating a single request, and that you can actually feed the output of one model as an input to another! This is called chaining, and it opens to the doors to more complex, multi-modal use cases.\n",
    "\n",
    "In this exercise, you'll practice model chaining to identify the language used in an audio file. You'll do this by bringing together OpenAI's audio transcription functionality and its text models with only a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da011600-9857-44ca-aecc-bb17a548e0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the audio.wav file\n",
    "audio_file = open(\"Recording_dutch.m4a\", \"rb\")\n",
    "\n",
    "# Create a transcription request using audio_file\n",
    "audio_response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
    "\n",
    "# Create a request to the API to identify the language spoken\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\":\"user\", \"content\":\"what language is used in: \" + audio_response.text}]\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70d55f5-63c4-4beb-9095-714ceb983513",
   "metadata": {},
   "source": [
    "#### Creating meeting summaries\n",
    "Time for business! One time-consuming task that many find themselves doing day-to-day is taking meeting notes to summarize attendees, discussion points, next steps, etc.\n",
    "\n",
    "In this exercise, you'll use AI to augment this task to not only save a substantial amount of time, but also to empower attendees to focus on the discussion rather than administrative tasks. You've been provided with a recording from DataCamp's Q2 Roadmap webinar, which summarizes what DataCamp will be releasing during that quarter. You'll chain the Whisper model with a text or chat model to discover which courses will be launched in Q2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d687f-2cba-4cb7-ad53-708ffcd832aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the datacamp-q2-roadmap.mp3 file\n",
    "audio_file = open(\"datacamp-q2-roadmap-short.mp3\", \"rb\")\n",
    "\n",
    "# Create a transcription request using audio_file\n",
    "audio_response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
    "\n",
    "# Create a request to the API to summarize the transcript into bullet points\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"List the courses that DataCamp will be making as bullet points.\" + audio_response.text}\n",
    "    ],\n",
    "    max_tokens=100\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d25c169-31a1-4012-afce-a04d02138a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
