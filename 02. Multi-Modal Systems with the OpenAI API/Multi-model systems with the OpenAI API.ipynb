{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "197194cc-5b0e-45b9-bef9-4817e2d68ee5",
   "metadata": {},
   "source": [
    "# Multi-model Systems with the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a75f7cc-caca-43a8-b0c3-85ffbecb13d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Use current working directory and go one level up\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Now you can import your config\n",
    "from config import api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542e446f-c827-4328-bebe-844d1d80ea56",
   "metadata": {},
   "source": [
    "## Chapter 1 - Beyond-to-text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f9b28c6-d9ae-4564-94fc-d58f9d15495a",
   "metadata": {},
   "source": [
    "### Section 1.1 - Speech-to-text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1f9a09-886d-4883-abcb-8612b87cbf8a",
   "metadata": {},
   "source": [
    "#### Creating a podcast transcript\n",
    "\n",
    "The OpenAI API Audio endpoint provides access to the different models, which can be used for speech-to-text transcription and translation. In this exercise, you'll create a transcript from a DataFramed podcast episode with OpenAI Developer, Logan Kilpatrick.\n",
    "\n",
    "If you'd like to hear more from Logan, check out the full ChatGPT and the OpenAI Developer Ecosystem podcast episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b19cc824-1412-4f3a-a999-04a6cd6faee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi there, Logan, thank you for joining us on the show today. Thanks for having me. I'm super excited about this. Brilliant. We're going to dive right in, and I think ChatGPT is maybe the most famous AI product that you have at OpenAI, but I'd just like to get an overview of what all the other AIs that are available are. So I think two and a half years ago, OpenAI released the API that we still have available today, which is essentially our giving people access to these models. And for a lot of people, giving people access to the model that powers ChatGPT, which is our consumer-facing first-party application, which essentially just, in very simple terms, puts a nice UI on top of what was already available through our API for the last two and a half years. So it's sort of democratizing the access to this technology through our API. And if you want to just play around with it as an end user, we have ChatGPT available to the world as well.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the openai-audio.mp3 file\n",
    "audio_file = open(\"audio-logan-advocate-openai.mp3\", \"rb\")\n",
    "\n",
    "# Create a transcript from the audio file\n",
    "response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
    "\n",
    "# Extract and print the transcript text\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e738cf34-19c6-4880-84e4-0907010bad4b",
   "metadata": {},
   "source": [
    "#### Transcribing a non-English language\n",
    "\n",
    "OpenAI's audio models can not only transcribe English speech but also perform well in speech in many other languages.\n",
    "\n",
    "In this exercise, you'll create a transcript from audio.m4a, which contains speech in Portuguese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "450c95cf-d4fc-4666-afa7-7b81707e1ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Olá, o meu nome é Eduardo, sou CTO no Datacamp. Espero que esteja a gostar deste curso que o James e eu criamos para você. Esta API permite enviar um áudio e trazer para inglês. O áudio original está em português.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the audio.m4a file\n",
    "audio_file = open(\"audio-portuguese.m4a\", \"rb\")\n",
    "\n",
    "# Create a transcript from the audio file\n",
    "response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fb8e64-0a19-4623-9796-bfcdae189da4",
   "metadata": {},
   "source": [
    "#### Translating Portuguese\n",
    "\n",
    "OpenAI's audio models can not only transcribe audio into its native language, but also support translation capabilities for creating English transcriptions.\n",
    "\n",
    "In this exercise, you'll return to the Portuguese audio, but this time, you'll translate it into English!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bea7327-3724-4f7e-9337-795bda8f5085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is Eduardo, I am a CTO at Datacamp. I hope you are enjoying this course that James and I have created for you. This API allows you to send an audio and bring it to English. The original audio is in Portuguese.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the audio.m4a file\n",
    "audio_file = open('audio-portuguese.m4a', \"rb\")\n",
    "\n",
    "# Create a translation from the audio file\n",
    "response = client.audio.translations.create(model=\"whisper-1\", file=audio_file)\n",
    "\n",
    "# Extract and print the translated text\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a50e9e6-78b9-43d1-af2c-753a833a02f4",
   "metadata": {},
   "source": [
    "### Section 1.2 - Text-to-speech (TTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f533e1-9dec-4924-9a82-509c061ab589",
   "metadata": {},
   "source": [
    "#### OpenAI's text-to-speech (TTS)\n",
    "OpenAI now provide models for creating human-like speech from a text input, so-called text-to-speech or TTS. OpenAI provide several voices to choose from, and they provide the ability to stream the response to local files or downstream applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "554430bd-8a09-4837-8815-74ddd45e7252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_286523/3595893031.py:11: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(\"output.mp3\")\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create the text-to-speech request\n",
    "response = client.audio.speech.create(\n",
    "  model=\"gpt-4o-mini-tts\",\n",
    "  voice=\"ballad\",\n",
    "  input=\"Hi! How's your day going?\"\n",
    ")\n",
    "\n",
    "# Stream the response to an MP3 file\n",
    "response.stream_to_file(\"output.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "530b0547-dcef-41d1-bad8-cd69f8e4491d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.write_to_file('test.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85616975-ed15-4735-8a73-7b882ed66df6",
   "metadata": {},
   "source": [
    "#### TTS in other languages!\n",
    "Let's have a go at some non-English text. Try sending the following text input to the model:\n",
    "\n",
    "`Dnes je krásný slunečný den.`\n",
    "\n",
    "The text is in the Czech language, which is spoken primarily in the Czech Republic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a8f9e96-8183-4821-9324-a4d1ba0e8038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_286523/3058821576.py:10: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(\"output.mp3\")\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Pass the non-English text to the model\n",
    "response = client.audio.speech.create(\n",
    "    model=\"gpt-4o-mini-tts\",\n",
    "    voice=\"coral\",\n",
    "    input=\"Dnes je krásný slunečný den.\"\n",
    ")\n",
    "\n",
    "response.stream_to_file(\"output.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61ed58c-e22f-4d28-ab81-10ac034c782c",
   "metadata": {},
   "source": [
    "### Section 1.3 - Content moderation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfeb309f-9fab-4e37-826c-26ca21d69dff",
   "metadata": {},
   "source": [
    "#### Requesting moderation\n",
    "Aside from text and chat completion models, OpenAI provides models with other capabilities, including text moderation. OpenAI's text moderation model is designed for evaluating prompts and responses to determine if they violate OpenAI's usage policies, including inciting hate speech and promoting violence.\n",
    "\n",
    "In this exercise, you'll test out OpenAI's moderation functionality on a sentence that may have been flagged as containing violent content using traditional word detection algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "436368ff-6e2a-4fa5-900a-1554d8d0fb3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CategoryScores(harassment=5.243551186140394e-06, harassment_threatening=1.1516095810293336e-06, hate=4.767837526742369e-05, hate_threatening=3.2021056028952444e-08, illicit=None, illicit_violent=None, self_harm=9.466615438213921e-07, self_harm_instructions=5.426785065765216e-08, self_harm_intent=1.5536235764557205e-07, sexual=3.545879735611379e-06, sexual_minors=1.1304399549771915e-06, violence=0.0001064608441083692, violence_graphic=1.086988686438417e-05, self-harm=9.466615438213921e-07, sexual/minors=1.1304399549771915e-06, hate/threatening=3.2021056028952444e-08, violence/graphic=1.086988686438417e-05, self-harm/intent=1.5536235764557205e-07, self-harm/instructions=5.426785065765216e-08, harassment/threatening=1.1516095810293336e-06)\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a request to the Moderation endpoint\n",
    "response = client.moderations.create(\n",
    "    model=\"text-moderation-latest\",\n",
    "    input=\"My favorite book is To Kill a Mockingbird.\"\n",
    ")\n",
    "\n",
    "# Print the category scores\n",
    "print(response.results[0].category_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75cfcd93-c5e1-4e16-bbca-53f9f91c1e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.results[0].flagged # none of the categories flags True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507b7b9a-47e5-4e7e-8be1-627119098277",
   "metadata": {},
   "source": [
    "#### Examining moderation category scores\n",
    "\n",
    "The same request you created in the last exercise to the Moderation endpoint has been run again, sending the sentence \"My favorite book is To Kill a Mockingbird.\" to the model. The response from the API has been printed for you, and is available as response.\n",
    "\n",
    "Extract the category scores to determine the correct interpretation from the following list of statements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4421851e-72b4-4381-bb1a-b9f3b9aacd80",
   "metadata": {},
   "source": [
    "## Chapter 2 - Creating customer call transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d261710b-4a17-4daa-a9ff-5d88f8b95783",
   "metadata": {},
   "source": [
    "### Section 2.1 - Creating customer call transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8cc79f-ac09-40d9-88c9-942cf9a10a08",
   "metadata": {},
   "source": [
    "#### Transcribing customer calls\n",
    "You're working as an AI Engineer at DataCamp, which has an international learner base spanning 180+ countries. Their customer support team want to test receiving customer queries via phone call; however, they need your support to design a system to help their agents handle these requests.\n",
    "\n",
    "To start, you will use the OpenAI API to transcribe their customer calls in the language they were recorded in.\n",
    "\n",
    "As this is a case study, less code will be provided for you than in the previous chapter. If you struggle, don't give up, you can do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd65b52d-2962-4f27-b540-fb69ce6fd05a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao! Vorrei imparare l'AI con DataCamp, ma cosa posso usare? PyTorch, l'API di OpenAI, Lungchain o qualcos'altro?\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the customer_call.wav file\n",
    "audio_file = open(\"customer_call_it_v2.wav\",\"rb\")\n",
    "\n",
    "# Create a transcript from the audio file\n",
    "response = client.audio.transcriptions.create(\n",
    "    model='whisper-1',\n",
    "    file=audio_file\n",
    ")\n",
    "transcript = response.text\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8410033-74e5-485f-bb5c-88c3856411e3",
   "metadata": {},
   "source": [
    "#### Deriving the customer's language\n",
    "\n",
    "Now that you have a transcript of the customer call, you need to derive the language used to eventually translate the response back to the customer in their native language. You'll use an OpenAI chat model to identify the language.\n",
    "\n",
    "The output from the model should be standardized to a country code; for example, \"en\" for English, \"fr\" for French, and so on.\n",
    "\n",
    "The transcript you created in the previous exercise is available as transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "53a8183b-2282-4184-9963-d40311aa583d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Complete a request identify the country code from the transcript\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \n",
    "    \"content\":f\"Indentify the language of the following text and response only with the country code (e.g 'en', 'nl', 'uk', 'fr': {transcript}\"}]\n",
    ")\n",
    "\n",
    "# Extract the country code from the response\n",
    "country_code = response.choices[0].message.content\n",
    "print(country_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15ebf1b-7309-4c6b-ae48-919ff016a6f8",
   "metadata": {},
   "source": [
    "#### Translating the transcript into English\n",
    "\n",
    "With the customer call transcript created, it's time to translate it into English for processing.\n",
    "\n",
    "The `transcript` you created previously is available as transcript, and the country code is stored in `country_code`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5d49e91-29cf-45b6-8c7c-6898a55b49e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I would like to learn AI with DataCamp, but what can I use? PyTorch, the OpenAI API, Langchain, or something else?\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Translate the transcript into English\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=[{\"role\": \"user\",\n",
    "        \"content\":f\"Please translate the following transcript: {transcript} from the country code {country_code} into English\"}]\n",
    " \n",
    ")\n",
    "\n",
    "# Extract the translated transcript text\n",
    "en_transcript = response.choices[0].message.content\n",
    "print(en_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8809747-3dae-45a7-8570-2c00c346c667",
   "metadata": {},
   "source": [
    "#### Fixing translation mistakes\n",
    "As you saw, translations aren't always perfect, particularly if the transcript contains names or references outside of the model's knowledge. In this exercise, you'll use another call to the chat model to fix these incorrect words.\n",
    "\n",
    "The English transcript you created in the previous exercise is available as `en_transcript`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "407e0e01-f26e-405e-8318-5b54765aaaf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I would like to learn AI with DataCamp, but what can I use? PyTorch, the OpenAI API, LangChain, or something else?\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Fix the mistake in the transcript\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": f\"You are an AI assistant that corrects transcripts by fixing names and terminology, leaving the rest of the transcript unchanged. Please refine the following transcript: {en_transcript}\"}]\n",
    ")\n",
    "\n",
    "corrected_text = response.choices[0].message.content\n",
    "print(corrected_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492d8ce2-b6dd-4723-a44e-6506df911dd0",
   "metadata": {},
   "source": [
    "### Section 2.2 Generating a customer response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3eec44-b68f-42ba-8e14-635a00b740a8",
   "metadata": {},
   "source": [
    "#### Moderating the customer call\n",
    "To ensure quality and safety, you'll now moderate the processed customer message. This step helps identify and flag potentially inappropriate content such as harassment.\n",
    "\n",
    "The corrected transcript from the previous exercise is available as `corrected_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5cfcfd71-3b10-4d3d-b7eb-a6af03feba94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content is safe from harassment.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Send the moderation request\n",
    "response = client.moderations.create(\n",
    "    model='text-moderation-latest',\n",
    "    input=corrected_text\n",
    ")\n",
    "\n",
    "# Extract scores and convert to dictionary\n",
    "scores = response.results[0].category_scores.model_dump()\n",
    "\n",
    "# Extract harassment score\n",
    "harassment_score = scores['harassment']\n",
    "\n",
    "if harassment_score>0.8:\n",
    "    print(\"Content flagged for harassment!\")\n",
    "else:\n",
    "    print(\"Content is safe from harassment.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5710fbd7-c869-4270-a452-50e5346e5c10",
   "metadata": {},
   "source": [
    "#### Generating a tailored response\n",
    "Now that the customer inquiry passed moderation, it's time to generate a tailored response.\n",
    "\n",
    "To help the chatbot respond accurately, you'll provide it with relevant context. Two documents are available:\n",
    "\n",
    "- faqs: common customer questions and answers\n",
    "- content_overview: relevant tracks, including descriptions and links\n",
    "\n",
    "The corrected transcript is still available as `corrected_text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43259f83-9794-4a2c-8167-5adaa172d1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "faqs = \"\\nQ: How can I upgrade my subscription?  \\nA: Log into your account, go to 'Account Settings' > 'Subscription,' and click 'Upgrade.' You will only pay the difference if upgrading from monthly to yearly. //\\n\\nQ: How do I contact DataCamp Customer Support?  \\nA: Use the live chat button in the bottom-right corner of the Help Center for 24/7 assistance. Alternatively, email support@datacamp.com or use the contact form. //\\n\\nQ: Does DataCamp offer content in multiple languages?  \\nA: Yes, many courses are available in languages like Spanish, Portuguese, German, and French. You can change the language in your account settings. //\\n\\nQ: Why did I lose access to my DataCamp Classroom?  \\nA: Classrooms are valid for six months. Reapply for a new Classroom to regain access. //\\n\\nQ: Can I integrate Data Connector with BI tools like PowerBI or Tableau?  \\nA: Yes, it integrates with tools like PowerBI, Tableau, and Looker. //\\n\\nQ: Can I invite non-teaching staff to my DataCamp Classroom?  \\nA: No, only teaching staff and students may join Classrooms. Non-teaching staff should apply for their own accounts. //\\n\\nQ: How do I prepare for a course before my Classroom starts?  \\nA: Use a free account to access the first chapter of courses or set an earlier start date during application. //\\n\\nQ: What happens if I cancel my subscription before upgrading?  \\nA: You will be charged the full yearly rate unless you reactivate your monthly subscription first by contacting Support. //\\n\\nQ: Where can I download all the course content?  \\nA: DataCamp does not allow downloading course content, but you can access it anytime online. //\\n\\nQ: Does DataCamp provide certification for Microsoft's AZ-900?  \\nA: Yes, DataCamp offers preparation for Microsoft's AZ-900 Certification through specialized courses. //\\n\\nQ: Can I earn certification for Microsoft’s PL-300 on DataCamp?  \\nA: Yes, DataCamp provides courses to prepare for Microsoft’s PL-300 Certification. //\\n\\nQ: What should I do if I experience video playback issues during a course?  \\nA: Check your internet connection, disable browser extensions, and clear your cache. If the issue persists, contact Support. //\\n\\nQ: Will I receive a grade or bonus XP when I finish a course?  \\nA: No grades are given, but you will earn XP upon completing a course. Bonus XP may apply during special events. //\\n\\nQ: Why is my XP decreasing?  \\nA: XP may decrease if content is updated or removed from the platform. Your overall progress remains unaffected. //\\n\\nQ: Can I reset my account's XP and progress?  \\nA: No, resetting XP and progress is not possible on DataCamp. //\\n\\nQ: Can I use XP to redeem content on DataCamp?  \\nA: No, XP is only used to track learning progress and cannot be redeemed for content. //\\n\\nQ: How can I share my finished DataCamp projects?  \\nA: You can download your completed projects as PDFs or share them via a public link provided by DataCamp. //\\n\\nQ: How much does a DataCamp statement of accomplishment cost?  \\nA: Statements of accomplishment are free and automatically available after completing a course or track. //\\n\\nQ: How can I share my statement of accomplishment on LinkedIn?  \\nA: Download your statement as a PDF and upload it to LinkedIn under 'Licenses & Certifications.' Include the issuing organization as 'DataCamp.' //\\n\\nQ: Can I update my name on a statement of accomplishment?  \\nA: Yes, update your name in your account settings before downloading the statement again. //\\n\\nQ: What are recent updates to DataCamp’s content?  \\nA: Recent updates include new courses and features released quarterly, such as Q1 2025 updates covering advanced Python topics and machine learning tools. //\\n\\nQ: What is DataCamp Certification?  \\nA: DataCamp Certification is an official recognition of your skills as a Data Scientist, Data Analyst, or Data Engineer. It includes timed exams and a practical case study based on real-world scenarios. //\\n\\nQ: Do I need a subscription to access certification?  \\nA: Yes, certification is available to individual subscribers and some business accounts. //\\n\\nQ: What languages are supported for certifications?  \\nA: Certifications are currently only available in English. //\\n\\nQ: Do I need to know both R and Python for certification?  \\nA: No, you can choose to complete your exams in either R or Python. //\\n...\\n\"\n",
    "content_overview = \"\\nContent Type: Career Track // Title: Associate AI Engineer for Developers // Description: Begin integrating AI into software applications and gain the career-building skills you need to succeed as an AI Engineer! You'll use Large Language Models (LLMs), prompt engineering, chatbots, recommendation engines, and vector databases. Explore OpenAI API, Hugging Face, LangChain, and Pinecone. // Technology: Python // Duration: 30 hours // Released: Aug 14, 2024 // URL: https://www.datacamp.com/tracks/associate-ai-engineer-for-developers\\n\\nContent Type: Skills Track // Title: Llama Fundamentals // Description: This track equips you with the skills to implement Llama 3 for tasks like summarization, text generation, and model fine-tuning. Explore how to integrate open-source Llama models into various projects. // Technology: Llama // Duration: 5 hours // Released: Dec 20, 2024 // URL: https://www.datacamp.com/tracks/llama-fundamentals\\n\\nContent Type: Skills Track // Title: OpenAI Fundamentals // Description: Learn to use the OpenAI API in Python to create AI applications like chatbots, semantic search, and recommendation systems. Hands-on coding exercises include advanced prompting techniques and embedding models. // Technology: OpenAI // Duration: 13 hours // Released: Jun 13, 2024 // URL: https://www.datacamp.com/tracks/openai-fundamentals\\n\\nContent Type: Skills Track // Title: Deep Learning in Python // Description: Dive into deep learning with PyTorch! Build models for real-world tasks, including electricity consumption prediction, cloud classification, and language identification. Work with CNNs, RNNs, and Transformers. // Technology: PyTorch // Duration: 18 hours // Released: Mar 13, 2025 // URL: https://www.datacamp.com/tracks/deep-learning-in-python\\n\\nContent Type: Skills Track // Title: ChatGPT Fundamentals // Description: Master the basics of ChatGPT, effective prompting, and workflow automation. Learn how businesses use ChatGPT to optimize operations and enhance AI-driven solutions. // Technology: ChatGPT // Duration: 3 hours // Released: Sep 20, 2024 // URL: https://www.datacamp.com/tracks/chatgpt-fundamentals\\n...\\n\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "879413a8-b4fe-448b-b136-8b900905f35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataCamp offers a variety of courses and tracks to help you learn AI, depending on your interests and goals. Here are a few options you can consider:\n",
      "\n",
      "1. **Associate AI Engineer for Developers**: This career track focuses on integrating AI into software applications, covering Large Language Models (LLMs), prompt engineering, chatbots, and more. You'll also get to explore tools like OpenAI API, Hugging Face, LangChain, and Pinecone. It has a duration of 30 hours and is designed to equip you with the necessary skills to succeed as an AI Engineer. You can find this track [here](https://www.datacamp.com/tracks/associate-ai-engineer-for-developers).\n",
      "\n",
      "2. **OpenAI Fundamentals**: If you're specifically interested in using the OpenAI API, this skills track teaches you how to create AI applications such as chatbots and recommendation systems, incorporating advanced prompting techniques as well. This track lasts for 13 hours, and you can explore it [here](https://www.datacamp.com/tracks/openai-fundamentals).\n",
      "\n",
      "3. **Deep Learning in Python**: For those interested in deep learning, this skills track dives into PyTorch to build models for real-world tasks. It covers various neural network architectures, including CNNs, RNNs, and Transformers, over a duration of 18 hours. You can check it out [here](https://www.datacamp.com/tracks/deep-learning-in-python).\n",
      "\n",
      "Feel free to explore these options and select the one that aligns with your career goals and interests!\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Complete the prompt\n",
    "instruction_prompt = f\"\"\"\n",
    "#### Role\n",
    "You are a professional AI support assistant for DataCamp. You help with:\n",
    "- Sales (pricing, plans, billing)\n",
    "- Content (courses, recommendations, feedback)\n",
    "- Marketing (partnerships, collaborations)\n",
    "\n",
    "#### How to Respond\n",
    "1. Use the FAQs: {faqs}\n",
    "2. Use the content overview: {content_overview} \n",
    "3. Respond clearly and concisely in up to 3 paragraphs.\n",
    "4. If unsure, direct the user to support@datacamp.com.\n",
    "\"\"\"\n",
    "\n",
    "# Generate response\n",
    "response = client.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    messages=[{\"role\":\"system\",\"content\": instruction_prompt},\n",
    "    {\"role\":\"user\", \"content\":corrected_text}]\n",
    ")\n",
    "\n",
    "chatbot_reply = response.choices[0].message.content\n",
    "print(chatbot_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "889073a8-35b1-4ee3-a977-0b2e3e043ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'harassment': 3.5760862374445423e-05, 'harassment_threatening': 1.0533901331655215e-05, 'hate': 1.7152413533949584e-07, 'hate_threatening': 8.38202424802148e-07, 'illicit': None, 'illicit_violent': None, 'self_harm': 6.552371587531525e-07, 'self_harm_instructions': 3.247230552005931e-06, 'self_harm_intent': 2.563845782788121e-06, 'sexual': 1.994265039684251e-05, 'sexual_minors': 1.261122832829642e-07, 'violence': 0.0006444415776059031, 'violence_graphic': 2.028420385613572e-05, 'self-harm': 6.552371587531525e-07, 'sexual/minors': 1.261122832829642e-07, 'hate/threatening': 8.38202424802148e-07, 'violence/graphic': 2.028420385613572e-05, 'self-harm/intent': 2.563845782788121e-06, 'self-harm/instructions': 3.247230552005931e-06, 'harassment/threatening': 1.0533901331655215e-05}\n",
      "AI Response is safe.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Send the moderation request\n",
    "response = client.moderations.create(\n",
    "    model=\"text-moderation-latest\",\n",
    "    input=chatbot_reply\n",
    ")\n",
    "\n",
    "# Extract scores and convert to dictionary\n",
    "scores = response.results[0].category_scores.model_dump()\n",
    "print(scores)\n",
    "\n",
    "if all(score>0.7 for score in scores.values()):\n",
    "    print(\"AI Response flagged for moderation!\")\n",
    "    chatbot_reply = \"\"\"I'm sorry, but I can't provide a response to that request. Please contact support@datacamp.com for further assistance.\"\"\"\n",
    "else:\n",
    "    print(\"AI Response is safe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f715d3f-c3d7-47ce-b581-c09a8cd2db47",
   "metadata": {},
   "source": [
    "### Section 2.3 - Creating a speech response for customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "52c8c9a6-c10f-4e8d-a3ea-6bdc9aacbe71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataCamp offre una varietà di corsi e percorsi per aiutarti ad apprendere l'IA, a seconda dei tuoi interessi e obiettivi. Ecco alcune opzioni che puoi considerare:\n",
      "\n",
      "1. **Ingegnere AI Associato per Sviluppatori**: Questo percorso professionale si concentra sull'integrazione dell'IA nelle applicazioni software, coprendo Modelli Linguistici di Grandi Dimensioni (LLM), ingegneria dei prompt, chatbot e altro ancora. Avrai anche la possibilità di esplorare strumenti come OpenAI API, Hugging Face, LangChain e Pinecone. Ha una durata di 30 ore ed è progettato per fornirti le competenze necessarie per avere successo come Ingegnere AI. Puoi trovare questo percorso [qui](https://www.datacamp.com/tracks/associate-ai-engineer-for-developers).\n",
      "\n",
      "2. **Fondamenti di OpenAI**: Se sei particolarmente interessato a utilizzare l'API di OpenAI, questo percorso di competenze ti insegna come creare applicazioni AI come chatbot e sistemi di raccomandazione, incorporando anche tecniche avanzate di prompting. Questo percorso dura 13 ore e puoi esplorarlo [qui](https://www.datacamp.com/tracks/openai-fundamentals).\n",
      "\n",
      "3. **Deep Learning in Python**: Per coloro che sono interessati al deep learning, questo percorso di competenze esplora PyTorch per costruire modelli per compiti reali. Copre varie architetture di reti neurali, inclusi CNN, RNN e Transformer, per una durata di 18 ore. Puoi controllarlo [qui](https://www.datacamp.com/tracks/deep-learning-in-python).\n",
      "\n",
      "Sentiti libero di esplorare queste opzioni e scegliere quella che si allinea con i tuoi obiettivi professionali e interessi!\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Translate chatbot reply\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": f\"Translate the following text from English to {country_code}. Only return the translated text.\"},\n",
    "        {\"role\": \"user\", \"content\": chatbot_reply}\n",
    "    ],\n",
    "    max_completion_tokens=500 \n",
    ")\n",
    "\n",
    "# Extract translated text\n",
    "translated_reply = response.choices[0].message.content\n",
    "print(translated_reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0b6478-5cfd-4df5-a3d2-a634c7314041",
   "metadata": {},
   "source": [
    "#### Preparing the spoken response\n",
    "\n",
    "You've made it to the final step of the case study! Your task now is to convert the tailored, translated response into speech. Since the customer submitted their query via audio, they'll receive an audio reply in return—how cool is that?\n",
    "\n",
    "The translated reply from the previous exercise is available as translated_reply."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4b3848ef-1b09-40be-a446-40a092c32844",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_286523/3112500670.py:11: DeprecationWarning: Due to a bug, this method doesn't actually stream the response content, `.with_streaming_response.method()` should be used instead\n",
      "  response.stream_to_file(\"output.mp3\")\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create the text-to-speech request\n",
    "response = client.audio.speech.create(\n",
    "    model=\"gpt-4o-mini-tts\",\n",
    "    voice=\"onyx\",\n",
    "    input=translated_reply\n",
    ")\n",
    "\n",
    "# Stream the response to an MP3 file\n",
    "response.stream_to_file(\"output.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01705177-8199-4780-885e-a8e7c82be36f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
