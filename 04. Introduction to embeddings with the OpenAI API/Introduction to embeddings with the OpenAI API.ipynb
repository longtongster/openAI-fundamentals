{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1d70910-bf77-4e6c-a8ce-b631c1776b32",
   "metadata": {},
   "source": [
    "# Introduction to embeddings with the OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13491355-3387-4481-b804-dc576a73430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Use current working directory and go one level up\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Now you can import your config\n",
    "from config import api_key\n",
    "\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8977509-04bd-43cf-b95d-ecf1be6ee250",
   "metadata": {},
   "source": [
    "## Chapter 1 - What are embeddings?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed2408a-c268-41f9-924d-b067c1d330d0",
   "metadata": {},
   "source": [
    "### Section 1.1 - The wonderful world of embeddings!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb13847-eb76-48ea-b9b5-81e94f8ecb14",
   "metadata": {},
   "source": [
    "#### Creating embeddings\n",
    "In this exercise, you'll create your very first embeddings using the OpenAI API. Normally, to interact with the OpenAI API, you would need an OpenAI API key, and creating embeddings would incur a cost. However, you do not need to create or provide an API key in this course.\n",
    "\n",
    "The OPENAI_API_TOKEN placeholder has been provided in the code, which will send valid requests for the exercises in this course. If, at any point in the course, you hit a `RateLimitError`, pause for a moment and try again.\n",
    "\n",
    "The `OpenAI` class from the `openai` library will be imported for you throughout the course, and after this exercise, the `client` will be created for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dae09f-5e4d-460e-8193-97b9e9e7bf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an OpenAI client\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a request to obtain embeddings\n",
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=\"this is a text to embed\"\n",
    ")\n",
    "\n",
    "# Convert the response into a dictionary\n",
    "response_dict = response.model_dump()\n",
    "print(response_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcae13fd-4199-4bbb-82f0-bb6a139f7d18",
   "metadata": {},
   "source": [
    "#### Digging into the embeddings response\n",
    "\n",
    "You've been able to successfully use the OpenAI Embeddings endpoint to embed text data, and in this exercise, you'll finish this off by extracting information from the API's response.\n",
    "\n",
    "You've been provided with a response from the Embeddings API, which has already been converted into a dictionary and stored as `response_dict`. You'll need to extract the desired information from this dictionary. This `response_dict` has been printed for you, so you can view its contents and structure.\n",
    "\n",
    "Recall that the response is structured like a nested Python dictionary, and it can be accessed in much the same way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481d1469-7afd-42c7-9901-b8da5f9eacdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4531abbf-7f71-4649-b741-efba1933f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict['usage']['total_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65571901-2a44-461c-b39e-8d34511ce6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_dict['data'][0]['embedding'][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b01b27d-7b84-48d5-b0cb-77ed2b41959b",
   "metadata": {},
   "source": [
    "### Section 1.2 - Investigating the vector space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d53c37-a576-41f2-94bd-88d9753f6dcc",
   "metadata": {},
   "source": [
    "#### Embedding product descriptions\n",
    "\n",
    "**remark** - this is a rather complex exercise. It can help to break it down in peaces to understand the details.\n",
    "\n",
    "You've been provided with a list of dictionaries called `products`, which contains product information for different products sold by an online retailer. It's your job to embed the `'short_description'` for each product to enable semantic search for the retailer's website.\n",
    "\n",
    "Here's a preview of the `products` list of dictionaries:\n",
    "```\n",
    "products = [\n",
    "    {\n",
    "        \"title\": \"Smartphone X1\",\n",
    "        \"short_description\": \"The latest flagship smartphone with AI-powered features and 5G connectivity.\",\n",
    "        \"price\": 799.99,\n",
    "        \"category\": \"Electronics\",\n",
    "        \"features\": [\n",
    "            \"6.5-inch AMOLED display\",\n",
    "            \"Quad-camera system with 48MP main sensor\",\n",
    "            \"Face recognition and fingerprint sensor\",\n",
    "            \"Fast wireless charging\"\n",
    "        ]\n",
    "    },\n",
    "    ...\n",
    "]```\n",
    "\n",
    "An OpenAI client has already been created as assigned to client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2933c08-72df-43de-9bd5-9070eeddf726",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = [{'title': 'Smartphone X1',\n",
    "  'short_description': 'The latest flagship smartphone with AI-powered features and 5G connectivity.',\n",
    "  'price': 799.99,\n",
    "  'category': 'Electronics',\n",
    "  'features': ['6.5-inch AMOLED display',\n",
    "   'Quad-camera system with 48MP main sensor',\n",
    "   'Face recognition and fingerprint sensor',\n",
    "   'Fast wireless charging']},\n",
    " {'title': 'Luxury Diamond Necklace',\n",
    "  'short_description': 'Elegant necklace featuring genuine diamonds, perfect for special occasions.',\n",
    "  'price': 1499.99,\n",
    "  'category': 'Beauty',\n",
    "  'features': ['18k white gold chain',\n",
    "   '0.5 carat diamond pendant',\n",
    "   'Adjustable chain length',\n",
    "   'Gift box included']},\n",
    " {'title': 'RC Racing Car',\n",
    "  'short_description': 'High-speed remote-controlled racing car for adrenaline-packed fun.',\n",
    "  'price': 89.99,\n",
    "  'category': 'Toys',\n",
    "  'features': ['Top speed of 30 mph',\n",
    "   'Responsive remote control',\n",
    "   'Rechargeable battery',\n",
    "   'Durable construction']},\n",
    " {'title': 'Ultra HD 4K TV',\n",
    "  'short_description': 'Immerse yourself in stunning visuals with this 65-inch 4K TV.',\n",
    "  'price': 1299.99,\n",
    "  'category': 'Electronics',\n",
    "  'features': ['65-inch 4K UHD display',\n",
    "   'Dolby Vision and HDR10+ support',\n",
    "   'Smart TV with streaming apps',\n",
    "   'Voice remote included']},\n",
    " {'title': 'Glowing Skin Serum',\n",
    "  'short_description': 'Revitalize your skin with this nourishing serum for a radiant glow.',\n",
    "  'price': 39.99,\n",
    "  'category': 'Beauty',\n",
    "  'features': ['Hyaluronic acid and vitamin C',\n",
    "   'Hydrates and reduces fine lines',\n",
    "   'Suitable for all skin types',\n",
    "   'Cruelty-free']},\n",
    " {'title': 'LEGO Space Shuttle',\n",
    "  'short_description': 'Build your own space adventure with this LEGO space shuttle set.',\n",
    "  'price': 49.99,\n",
    "  'category': 'Toys',\n",
    "  'features': ['359 pieces for creative building',\n",
    "   'Astronaut minifigure included',\n",
    "   'Compatible with other LEGO sets',\n",
    "   'For ages 7+']},\n",
    " {'title': 'Wireless Noise-Canceling Headphones',\n",
    "  'short_description': 'Enjoy immersive audio and block out distractions with these headphones.',\n",
    "  'price': 199.99,\n",
    "  'category': 'Electronics',\n",
    "  'features': ['Active noise cancellation',\n",
    "   'Bluetooth 5.0 connectivity',\n",
    "   'Long-lasting battery life',\n",
    "   'Foldable design for portability']},\n",
    " {'title': 'Luxury Perfume Gift Set',\n",
    "  'short_description': 'Indulge in a collection of premium fragrances with this gift set.',\n",
    "  'price': 129.99,\n",
    "  'category': 'Beauty',\n",
    "  'features': ['Five unique scents',\n",
    "   'Elegant packaging',\n",
    "   'Perfect gift for fragrance enthusiasts',\n",
    "   'Variety of fragrance notes']},\n",
    " {'title': 'Remote-Controlled Drone',\n",
    "  'short_description': 'Take to the skies and capture stunning aerial footage with this drone.',\n",
    "  'price': 299.99,\n",
    "  'category': 'Electronics',\n",
    "  'features': ['4K camera with gimbal stabilization',\n",
    "   'GPS-assisted flight',\n",
    "   'Remote control with smartphone app',\n",
    "   'Return-to-home function']},\n",
    " {'title': 'Luxurious Spa Gift Basket',\n",
    "  'short_description': 'Pamper yourself or a loved one with this spa gift basket full of relaxation goodies.',\n",
    "  'price': 79.99,\n",
    "  'category': 'Beauty',\n",
    "  'features': ['Bath bombs, body lotion, and more',\n",
    "   'Aromatherapy candles',\n",
    "   'Reusable wicker basket',\n",
    "   'Great for self-care']},\n",
    " {'title': 'Robot Building Kit',\n",
    "  'short_description': 'Learn robotics and coding with this educational robot building kit.',\n",
    "  'price': 59.99,\n",
    "  'category': 'Toys',\n",
    "  'features': ['Build and program your own robot',\n",
    "   'STEM learning tool',\n",
    "   'Compatible with Scratch and Python',\n",
    "   'Ideal for young inventors']},\n",
    " {'title': 'High-Performance Gaming Laptop',\n",
    "  'short_description': 'Dominate the gaming world with this powerful gaming laptop.',\n",
    "  'price': 1499.99,\n",
    "  'category': 'Electronics',\n",
    "  'features': ['Intel Core i7 processor',\n",
    "   'NVIDIA RTX graphics',\n",
    "   '144Hz refresh rate display',\n",
    "   'RGB backlit keyboard']},\n",
    " {'title': 'Natural Mineral Makeup Set',\n",
    "  'short_description': 'Enhance your beauty with this mineral makeup set for a flawless look.',\n",
    "  'price': 34.99,\n",
    "  'category': 'Beauty',\n",
    "  'features': ['Mineral foundation and eyeshadows',\n",
    "   'Non-comedogenic and paraben-free',\n",
    "   'Cruelty-free and vegan',\n",
    "   'Includes makeup brushes']},\n",
    " {'title': 'Interactive Robot Pet',\n",
    "  'short_description': 'Adopt your own robot pet that responds to your voice and touch.',\n",
    "  'price': 79.99,\n",
    "  'category': 'Toys',\n",
    "  'features': ['Realistic pet behaviors',\n",
    "   'Voice recognition and touch sensors',\n",
    "   'Teaches responsibility and empathy',\n",
    "   'Rechargeable battery']},\n",
    " {'title': 'Smart Thermostat',\n",
    "  'short_description': \"Control your home's temperature and save energy with this smart thermostat.\",\n",
    "  'price': 129.99,\n",
    "  'category': 'Electronics',\n",
    "  'features': ['Wi-Fi connectivity',\n",
    "   'Energy-saving features',\n",
    "   'Compatible with voice assistants',\n",
    "   'Easy installation']},\n",
    " {'title': 'Designer Makeup Brush Set',\n",
    "  'short_description': 'Upgrade your makeup routine with this premium designer brush set.',\n",
    "  'price': 59.99,\n",
    "  'category': 'Beauty',\n",
    "  'features': ['High-quality synthetic bristles',\n",
    "   'Chic designer brush handles',\n",
    "   'Complete set for all makeup needs',\n",
    "   'Includes stylish carrying case']},\n",
    " {'title': 'Remote-Controlled Dinosaur Toy',\n",
    "  'short_description': 'Roar into action with this remote-controlled dinosaur toy with lifelike movements.',\n",
    "  'price': 49.99,\n",
    "  'category': 'Toys',\n",
    "  'features': ['Realistic dinosaur sound effects',\n",
    "   'Walks and roars like a real dinosaur',\n",
    "   'Remote control included',\n",
    "   'Educational and entertaining']},\n",
    " {'title': 'Wireless Charging Dock',\n",
    "  'short_description': 'Charge your devices conveniently with this sleek wireless charging dock.',\n",
    "  'price': 39.99,\n",
    "  'category': 'Electronics',\n",
    "  'features': ['Qi wireless charging technology',\n",
    "   'Supports multiple devices',\n",
    "   'LED charging indicators',\n",
    "   'Compact and stylish design']},\n",
    " {'title': 'Luxury Skincare Set',\n",
    "  'short_description': 'Elevate your skincare routine with this luxurious skincare set.',\n",
    "  'price': 179.99,\n",
    "  'category': 'Beauty',\n",
    "  'features': ['Premium anti-aging ingredients',\n",
    "   'Hydrating and rejuvenating formulas',\n",
    "   'Complete skincare regimen',\n",
    "   'Elegant packaging']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af8893-eb60-463e-a230-d4127f759f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract a list of product short descriptions from products\n",
    "product_descriptions = [product['short_description'] for product in products]\n",
    "\n",
    "# Create embeddings for each product description\n",
    "response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=product_descriptions)\n",
    "\n",
    "response_dict = response.model_dump()\n",
    "\n",
    "# Extract the embeddings from response_dict and store in products\n",
    "for i, product in enumerate(products):\n",
    "    product['embedding'] = response_dict['data'][i]['embedding']   \n",
    "     \n",
    "# print(products[0].items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9149b559-f9b1-4dcb-b0a7-76ca2aeccc11",
   "metadata": {},
   "source": [
    "#### Visualizing the embedded descriptions\n",
    "\n",
    "Now that you've created embeddings from the product descriptions, it's time to explore them! You'll use t-SNE to reduce the number of dimensions in the embeddings data from 1,536 to two, which will make the data much easier to visualize.\n",
    "\n",
    "You'll start with the products list of dictionaries you worked with in the last exercise, containing product information and the embeddings you created from the 'short_description'. As a reminder, here's a preview of products:\n",
    "```\n",
    "products = [\n",
    "    {\n",
    "        \"title\": \"Smartphone X1\",\n",
    "        \"short_description\": \"The latest flagship smartphone with AI-powered features and 5G connectivity.\",\n",
    "        \"price\": 799.99,\n",
    "        \"category\": \"Electronics\",\n",
    "        \"features\": [\n",
    "            \"6.5-inch AMOLED display\",\n",
    "            \"Quad-camera system with 48MP main sensor\",\n",
    "            \"Face recognition and fingerprint sensor\",\n",
    "            \"Fast wireless charging\"\n",
    "        ],\n",
    "        \"embedding\": [-0.014650369994342327, ..., 0.008677126839756966]\n",
    "    },\n",
    "    ...\n",
    "]```\n",
    "\n",
    "`matplotlib.pyplot` and `numpy` have been imported as `plt` and `np`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae9156a-5c14-4dbd-8748-c89e6c015947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a0c7e0-fc8a-4b32-8338-678e067bb3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reviews and embeddings lists using list comprehensions\n",
    "categories = [product['category'] for product in products]\n",
    "embeddings = [product['embedding'] for product in products]\n",
    "\n",
    "# Reduce the number of embeddings dimensions to two using t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=5)\n",
    "embeddings_2d = tsne.fit_transform(np.array(embeddings))\n",
    "\n",
    "# Create a scatter plot from embeddings_2d\n",
    "plt.scatter(embeddings_2d[:,0], embeddings_2d[:,1])\n",
    "\n",
    "for i, category in enumerate(categories):\n",
    "    plt.annotate(category, (embeddings_2d[i, 0], embeddings_2d[i, 1]))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78bc843-1e20-441b-9e9c-f65c6211de09",
   "metadata": {},
   "source": [
    "### Section 1.3 - Text similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e367505-e6b1-46db-a9ce-a801bd6fe50e",
   "metadata": {},
   "source": [
    "#### Computing cosine distances\n",
    "To identify the most semantically similar texts, you need to apply a distance metric. A popular choice is the cosine distance.\n",
    "\n",
    "In this exercise, you've been provided with four vectors: `A`, `B`, `C`, and `D`. It's your task to find out which vector is most similar to `A` using cosine distance.\n",
    "\n",
    "Which vector is the most similar to `A`?\n",
    "\n",
    "`distance` has already been imported from scipy.spatial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c99a640f-ac9b-470e-8833-6b48d2e8c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cc75cc-cbd7-40f4-abe8-7de2ac621561",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [3, 1, 4]\n",
    "B = [1, 5, 9]\n",
    "C = [2, 6, 5]\n",
    "D = [3, 5, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c574c5b4-370d-4db6-9c75-5e59e443368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(distance.cosine(A,B))\n",
    "print(distance.cosine(A,C))\n",
    "print(distance.cosine(A,D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49a69f4-8d3d-4a52-8923-e043774cdc87",
   "metadata": {},
   "source": [
    "#### More repeatable embeddings\n",
    "\n",
    "As you continue to work with embeddings, you'll find yourself making repeated calls to OpenAI's embedding model. To make these calls in a more repeatable and modular way, it would be better to define a custom function called `create_embeddings()` that would output embeddings for any number of text inputs. In this exercise, you'll do just that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e85c065-e7bc-4009-aad0-069f97bf0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "short_description = 'The latest flagship smartphone with AI-powered features and 5G connectivity.'\n",
    "list_of_descriptions = ['Charge your devices conveniently with this sleek wireless charging dock.',\n",
    " 'Elevate your skincare routine with this luxurious skincare set.']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0916b40-bda9-416e-aace-a3539bbb1d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a create_embeddings function\n",
    "def create_embeddings(texts):\n",
    "  response = client.embeddings.create(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    input=texts\n",
    "  )\n",
    "  response_dict = response.model_dump()\n",
    "\n",
    "  return [data['embedding'] for data in response_dict['data']]\n",
    "\n",
    "# Embed short_description and print\n",
    "print(create_embeddings(short_description)[0])\n",
    "\n",
    "# Embed list_of_descriptions and print\n",
    "print(create_embeddings(list_of_descriptions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636f6727-2b4f-4e68-9252-0516cc6e799a",
   "metadata": {},
   "source": [
    "#### Finding the most similar product\n",
    "Being able to compute similarity between embeddings is a key step within embeddings applications. In this exercise, you'll return to the products list of dictionaries that you worked with previously, which contains the embedded short descriptions you also created earlier.\n",
    "\n",
    "You'll compare a piece of text to these embedded descriptions to identify the most similar description.\n",
    "\n",
    "`numpy` has been imported as `np`, and `distance` is available from `scipy.spatial`. A `create_embeddings()` function has already been defined for you and is available to use for creating embeddings from a single input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ea1312-2434-4dab-a9e6-0022acb1dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e970f253-7169-4dc1-9126-39073fe9e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the search text\n",
    "search_text = \"soap\"\n",
    "search_embedding = create_embeddings(search_text)[0]\n",
    "\n",
    "distances = []\n",
    "for product in products:\n",
    "  # Compute the cosine distance for each product description\n",
    "  dist = distance.cosine(search_embedding, product['embedding'])\n",
    "  distances.append(dist)\n",
    "\n",
    "# Find and print the most similar product short_description    \n",
    "min_dist_ind = np.argmin(distances)\n",
    "print(products[min_dist_ind]['short_description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03076511-ac4e-4ce7-aba8-fea172cc37bc",
   "metadata": {},
   "source": [
    "## Chapter 2 - Embedding for AI Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269dd369-24ca-40d2-ad0d-2c32c549d191",
   "metadata": {},
   "source": [
    "### Section 2.1 - Semantic search and enriched embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadee7e1-cf61-4d17-9a4a-c8f7dba3f785",
   "metadata": {},
   "source": [
    "#### Enriching embeddings\\\n",
    "\n",
    "Previously, when you embedded product information, you were limited to only embedding the product 'short_description', which captured some, but not all of the relevant product information available. In this exercise, you'll embed `'title'`, `'short_description'`, `'category'`, and `'features'` to capture much more information.\n",
    "\n",
    "Here's a reminder of the products list of dictionaries:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c63cf0a6-1703-4fae-b1ed-7ce1faf8caff",
   "metadata": {},
   "source": [
    "products = [\n",
    "    {\n",
    "        \"title\": \"Smartphone X1\",\n",
    "        \"short_description\": \"The latest flagship smartphone with AI-powered features and 5G connectivity.\",\n",
    "        \"price\": 799.99,\n",
    "        \"category\": \"Electronics\",\n",
    "        \"features\": [\n",
    "            \"6.5-inch AMOLED display\",\n",
    "            \"Quad-camera system with 48MP main sensor\",\n",
    "            \"Face recognition and fingerprint sensor\",\n",
    "            \"Fast wireless charging\"\n",
    "        ]\n",
    "    },\n",
    "    ...\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dd4f82-0fd3-4a52-8eda-908723193281",
   "metadata": {},
   "source": [
    "When combining the features into a single string, it should have the following structure:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b253e86b-7c1c-4330-87f9-01751f12e59f",
   "metadata": {},
   "source": [
    "Title: <product title>\n",
    "Description: <product description>\n",
    "Category: <product category>\n",
    "Features: <feature 1>; <feature 2>; <feature 3>; ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54e6d00-7991-49c9-8858-5188d185539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to combine the relevant features into a single string\n",
    "def create_product_text(product):\n",
    "  return f\"\"\"Title: {product['title']}\n",
    "Description: {product['short_description']}\n",
    "Category: {product['category']},\n",
    "Features: {\", \".join(product['features'])}\n",
    "\"\"\"\n",
    "\n",
    "# Combine the features for each product\n",
    "product_texts = [create_product_text(product) for product in products]\n",
    "\n",
    "# Create the embeddings from product_texts\n",
    "product_embeddings = create_embeddings(product_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ae1b5c-3a1e-45cc-a556-eed5353182ab",
   "metadata": {},
   "source": [
    "#### Sorting by similarity\n",
    "\n",
    "Now that you've embedded all of your features, the next step is to compute the similarities. In this exercise, you'll define a function called `find_n_closest()`, which computes the cosine distances between a query vector and a list of embeddings and returns the `n` smallest distances and their indexes.\n",
    "\n",
    "In the next exercise, you'll use this function to enable your semantic product search application.\n",
    "\n",
    "`distance` has been imported from `scipy.spatial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f891389-1a6e-4a6a-8e93-e2eaf73ae588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778fcd33-b290-436a-903f-c90c8525d2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_n_closest(query_vector, embeddings, n=3):\n",
    "  distances = []\n",
    "  for index, embedding in enumerate(embeddings):\n",
    "    # Calculate the cosine distance between the query vector and embedding\n",
    "    dist = distance.cosine(query_vector, embedding)\n",
    "    # Append the distance and index to distances\n",
    "    distances.append({\"distance\": dist, \"index\": index})\n",
    "  # Sort distances by the distance key\n",
    "  distances_sorted = sorted(distances, key=lambda x: x['distance'])\n",
    "  # Return the first n elements in distances_sorted\n",
    "  return distances_sorted[0:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a039cef6-4866-4f5d-ade6-9bea36944da3",
   "metadata": {},
   "source": [
    "#### Semantic search for products\n",
    "\n",
    "Time to put your `find_n_closest()` function to use! You'll test out your semantic product search on a test query, computing a sorted list of the five most semantically similar products, based on the enriched data you gave the model.\n",
    "\n",
    "Here's a reminder of the `find_n_closest()` function you created in the previous exercise:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "239b4643-5dd4-4da3-990a-55c2cb59b841",
   "metadata": {},
   "source": [
    "def find_n_closest(query_vector, embeddings, n=3):\n",
    "    distances = []\n",
    "    for index, embedding in enumerate(embeddings):\n",
    "        distance = spatial.distance.cosine(query_vector, embedding)\n",
    "        distances.append({\"distance\": distance, \"index\": index})\n",
    "    distances_sorted = sorted(distances, key=lambda x: x[\"distance\"])\n",
    "    return distances_sorted[0:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe00a9c8-44c4-479e-bdec-fdf1076bda32",
   "metadata": {},
   "source": [
    "The `create_embeddings()` function you created earlier is also available. Recall that it takes some text, and returns a list of lists containing the embeddings for each text. The `products` dictionary and the `product_embeddings` you created previously have also been loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc31cc-8535-4851-9f3e-e9c58f97b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the query vector from query_text\n",
    "query_text = \"computer\"\n",
    "query_vector = create_embeddings(query_text)[0]\n",
    "\n",
    "# Find the five closest distances\n",
    "hits = find_n_closest(query_vector, product_embeddings, n=5)\n",
    "\n",
    "print(f'Search results for \"{query_text}\"')\n",
    "for hit in hits:\n",
    "  # Extract the product at each index in hits\n",
    "  product = products[hit['index']]\n",
    "\n",
    "  print(product[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50333357-b11b-4693-9f44-e87511ba469c",
   "metadata": {},
   "source": [
    "### Section 2.2 - Recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450c4782-093e-4c24-a511-1d28ac4e9972",
   "metadata": {},
   "source": [
    "#### Product recommendation system\n",
    "\n",
    "In this exercise, you'll make a recommendation system for an online retailer that sells a variety of products. This system recommends three similar products to users who visit a product page but don't purchase, based on the last product they visited.\n",
    "\n",
    "You've been provided with a list of dictionaries of products available on the site,"
   ]
  },
  {
   "cell_type": "raw",
   "id": "069d159b-4313-4bc2-b28b-572a3d55f2e0",
   "metadata": {},
   "source": [
    "products = [\n",
    "    {\n",
    "        \"title\": \"Smartphone X1\",\n",
    "        \"short_description\": \"The latest flagship smartphone with AI-powered features and 5G connectivity.\",\n",
    "        \"price\": 799.99,\n",
    "        \"category\": \"Electronics\",\n",
    "        \"features\": [\n",
    "            \"6.5-inch AMOLED display\",\n",
    "            ...\n",
    "            \"Fast wireless charging\"\n",
    "        ]\n",
    "    },\n",
    "    ...\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30d589-25bf-4e16-86f4-4a3218cc31de",
   "metadata": {},
   "source": [
    "and a dictionary for the last product the user visited, stored in `last_product`.\n",
    "\n",
    "The following custom functions defined earlier in the course are also available for you to use:\n",
    "\n",
    "- `create_embeddings(texts)` → returns a list of embeddings for each text in `texts`.\n",
    "- `create_product_text(product)` → combines the `product` features into a single string for embedding.\n",
    "- `find_n_closest(query_vector, embeddings, n=3) `→ returns the `n` closest distances and their indexes between the `query_vector` and `embeddings`, based on cosine distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d420ac2-8220-48c2-b884-9ddfb3541929",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_product = {'title': 'Building Blocks Deluxe Set',\n",
    " 'short_description': 'Unleash your creativity with this deluxe set of building blocks for endless fun.',\n",
    " 'price': 34.99,\n",
    " 'category': 'Toys',\n",
    " 'features': ['Includes 500+ colorful building blocks',\n",
    "  'Promotes STEM learning and creativity',\n",
    "  'Compatible with other major brick brands',\n",
    "  'Comes with a durable storage container',\n",
    "  'Ideal for children ages 3 and up']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc66d3e-bb43-4634-a237-3daa1fe1477f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the features for last_product and each product in products\n",
    "last_product_text = create_product_text(last_product)\n",
    "product_texts = [create_product_text(product) for product in products]\n",
    "\n",
    "# Embed last_product_text and product_texts\n",
    "last_product_embeddings = create_embeddings(last_product_text)[0]\n",
    "product_embeddings = create_embeddings(product_texts)\n",
    "\n",
    "# Find the three smallest cosine distances and their indexes\n",
    "hits = find_n_closest(last_product_embeddings, product_embeddings, n=3)\n",
    "\n",
    "for hit in hits:\n",
    "  product = products[hit['index']]\n",
    "  print(product['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021bb44c-659e-4b6d-a040-a20e57287a6d",
   "metadata": {},
   "source": [
    "#### Adding user history to the recommendation engine\n",
    "For many recommendation cases, such as film or purchase recommendation, basing the next recommendation on one data point will be insufficient. In these cases, you'll need to embed all or some of the user's history for more accurate and relevant recommendations.\n",
    "\n",
    "In this exercise, you'll extend your product recommendation system to consider all of the products the user has previously visited, which are stored in a list of dictionaries called `user_history`.\n",
    "\n",
    "The following custom functions are available for you to use: `create_embeddings(texts)`, `create_product_text(product)`, and `find_n_closest(query_vector, embeddings, n=3)`. numpy has also been imported as `np`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efe49c0-fbc7-490f-a9bc-8782e8600389",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_history = [\n",
    " {'title': 'Remote-Controlled Dinosaur Toy',\n",
    "  'short_description': 'Roar into action with this remote-controlled dinosaur toy with lifelike movements.',\n",
    "  'price': 49.99,\n",
    "  'category': 'Toys',\n",
    "  'features': ['Realistic dinosaur sound effects',\n",
    "   'Walks and roars like a real dinosaur',\n",
    "   'Remote control included',\n",
    "   'Educational and entertaining']},\n",
    " {'title': 'Building Blocks Deluxe Set',\n",
    "  'short_description': 'Unleash your creativity with this deluxe set of building blocks for endless fun.',\n",
    "  'price': 34.99,\n",
    "  'category': 'Toys',\n",
    "  'features': ['Includes 500+ colorful building blocks',\n",
    "   'Promotes STEM learning and creativity',\n",
    "   'Compatible with other major brick brands',\n",
    "   'Comes with a durable storage container',\n",
    "   'Ideal for children ages 3 and up']}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7177089-67e5-429b-acf0-21fbe692bd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and embed the user_history, and calculate the mean embeddings\n",
    "history_texts = [create_product_text(article) for article in user_history]\n",
    "history_embeddings = create_embeddings(history_texts)\n",
    "mean_history_embeddings = np.mean(history_embeddings, axis=0)\n",
    "\n",
    "# Filter products to remove any in user_history\n",
    "products_filtered = [product for product in products if product not in user_history]\n",
    "\n",
    "# Combine product features and embed the resulting texts\n",
    "product_texts = [create_product_text(product) for product in products]\n",
    "product_embeddings = create_embeddings(product_texts)\n",
    "\n",
    "hits = find_n_closest(mean_history_embeddings, product_embeddings)\n",
    "\n",
    "for hit in hits:\n",
    "  product = products_filtered[hit['index']]\n",
    "  print(product['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a18af1-0366-41b3-a270-30ffc1c5d6ff",
   "metadata": {},
   "source": [
    "### Section 2.3. - Embeddings for classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117bac82-6c4f-49a1-b2b6-00d572ee2b8c",
   "metadata": {},
   "source": [
    "#### Embedding restaurant reviews\n",
    "\n",
    "One common classification task that embeddings are great for is sentiment analysis. In this and the following exercises, you'll navigate through the workflow of performing sentiment analysis using embeddings.\n",
    "\n",
    "You've been provided with a small sample of restaurant reviews, stored in `reviews`, and sentiment labels stored in `sentiments`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bf003f-dd99-4be4-9eff-1134571e8734",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = [{'label': 'Positive'},\n",
    "              {'label': 'Neutral'},\n",
    "              {'label': 'Negative'}]\n",
    "\n",
    "reviews = [\"The food was delicious!\",\n",
    "           \"The service was a bit slow but the food was good\",\n",
    "           \"The food was cold, really disappointing!\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe62e916-cdb5-45f7-9224-e0168d02c86e",
   "metadata": {},
   "source": [
    "You'll use zero-shot classification to classify the sentiment of these reviews by embedding the reviews and class labels.\n",
    "\n",
    "The `create_embeddings()` function you created previously is also available to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c365a9c-c0fc-4ba7-a503-298ff3424264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of class descriptions from the sentiment labels\n",
    "class_descriptions =  [sentiment['label'] for sentiment in sentiments]\n",
    "\n",
    "# Embed the class_descriptions and reviews\n",
    "class_embeddings = create_embeddings(class_descriptions)\n",
    "review_embeddings = create_embeddings(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d59b739-ef88-403b-b504-8aa026a0d954",
   "metadata": {},
   "source": [
    "#### Classifying review sentiment\n",
    "Now that you've calculated the embeddings, it's time to compute the cosine distances and extract the most similar label.\n",
    "\n",
    "You'll do this by defining a function called `find_closest()`, which can be used to compare the embeddings between one vector and multiple others, and return the nearest distance and its index. You'll then loop over the reviews and and use `find_closest()` to find the closest distance for each review, extracting the classified label using the index.\n",
    "\n",
    "The `class_embeddings` and `review_embeddings` objects you created in the last exercise are available for you to use, as well as the `reviews` and `sentiments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4561848-f00e-4a0b-8655-3655e348ae7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to return the minimum distance and its index\n",
    "def find_closest(query_vector, embeddings):\n",
    "  distances = []\n",
    "  for index, embedding in enumerate(embeddings):\n",
    "    dist = distance.cosine(query_vector, embedding)\n",
    "    distances.append({\"distance\": dist, \"index\": index})\n",
    "  return min(distances, key=lambda x: x[\"distance\"])\n",
    "\n",
    "for index, review in enumerate(reviews):\n",
    "  # Find the closest distance and its index using find_closest()\n",
    "  closest = find_closest(review_embeddings[index], class_embeddings)\n",
    "  # Subset sentiments using the index from closest\n",
    "  label = sentiments[closest['index']]['label']\n",
    "  print(f'\"{review}\" was classified as {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de7547e-3fbf-4f54-b445-471279dcee97",
   "metadata": {},
   "source": [
    "#### Embedding more detailed descriptions\n",
    "\n",
    "One of the last predicted labels didn't seem representative of the review; this was probably down to the lack of information being captured when we're only embedding the class labels. This time, descriptions of each class will be embedded instead, so the model better \"understands\" that you're classifying restaurant reviews.\n",
    "\n",
    "The following objects are available for you to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb5aad-a902-4c6d-9f96-253c1f9e87ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments = [{'label': 'Positive',\n",
    "               'description': 'A positive restaurant review'},\n",
    "              {'label': 'Neutral',\n",
    "               'description':'A neutral restaurant review'},\n",
    "              {'label': 'Negative',\n",
    "               'description': 'A negative restaurant review'}]\n",
    "\n",
    "reviews = [\"The food was delicious!\",\n",
    "           \"The service was a bit slow but the food was good\",\n",
    "           \"The food was cold, really disappointing!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b750339e-4804-48a5-80d3-2593671d972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and embed the descriptions from sentiments\n",
    "class_descriptions = [x['description'] for x in sentiments]\n",
    "class_embeddings = create_embeddings(class_descriptions)\n",
    "review_embeddings = create_embeddings(reviews)\n",
    "\n",
    "def find_closest(query_vector, embeddings):\n",
    "  distances = []\n",
    "  for index, embedding in enumerate(embeddings):\n",
    "    dist = distance.cosine(query_vector, embedding)\n",
    "    distances.append({\"distance\": dist, \"index\": index})\n",
    "  return min(distances, key=lambda x: x[\"distance\"])\n",
    "\n",
    "for index, review in enumerate(reviews):\n",
    "  closest = find_closest(review_embeddings[index], class_embeddings)\n",
    "  label = sentiments[closest['index']]['label']\n",
    "  print(f'\"{review}\" was classified as {label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f515064-9112-4d83-9175-22fc8bd6d41c",
   "metadata": {},
   "source": [
    "## Chapter 3 - Vector databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86a280-e7a3-492a-80f3-4dffc7973d6a",
   "metadata": {},
   "source": [
    "### Section 3.1 - Vector databases for embedding systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41854dfd-f6f6-4468-aac5-719253652a85",
   "metadata": {},
   "source": [
    "### Section 3.2 - Creating vector database with ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605dbe69-cc57-4f72-a698-b985fb5ece94",
   "metadata": {},
   "source": [
    "#### Getting started with ChromaDB\n",
    "\n",
    "In the following exercises, you'll use a vector database to embed and query 1000 films and TV shows from the Netflix dataset introduced in the video. The goal will be to use this data to generate recommendations based on a search query. To get started, you'll create the database and collection to store the data.\n",
    "\n",
    "`chromadb` is available for you to use, and the `OpenAIEmbeddingFunction()` has been imported from `chromadb.utils.embedding_functions`. As with the first two chapters, you don't need to provide an OpenAI API key in this chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408e7fec-e244-4bcf-903f-2c90f15af090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key= api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400f2ffe-5001-4c12-8364-c1521ee10103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a persistant client\n",
    "client = chromadb.PersistentClient(path=\"vector_db/\")\n",
    "\n",
    "# Create a netflix_title collection using the OpenAI Embedding function\n",
    "collection = client.create_collection(\n",
    "    name=\"netflix_titles\",\n",
    "    embedding_function=OpenAIEmbeddingFunction(model_name=\"text-embedding-3-small\", api_key=\"<OPENAI_API_TOKEN>\"),\n",
    "    get_or_create=True\n",
    ")\n",
    "\n",
    "# List the collections\n",
    "print(client.list_collections())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b109a7-0954-413a-8b94-c431ca5aa973",
   "metadata": {},
   "source": [
    "### Estimating embedding costs with tiktoken\n",
    "\n",
    "Now that we've created a database and collection to store the Netflix films and TV shows, we can begin embedding data.\n",
    "\n",
    "Before embedding a large dataset, it's important to do a cost estimate to ensure you don't go over any budget restraints. Because OpenAI models are priced by number of tokens inputted, we'll use OpenAI's `tiktoken` library to count the number of tokens and convert them into a dollar cost.\n",
    "\n",
    "You've been provided with `documents`, which is a list containing all of the data to embed. You'll iterate over the list, encode each document, and count the total number of tokens. Finally, you'll use the model's pricing to convert this into a cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f8743c-13bd-4b26-bbf1-3cf77d462e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    documents=json.load(f)\n",
    "\n",
    "print(f\"The dataset has {len(documents)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd4d62a-a698-4a15-94aa-7e1478073360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "# Load the encoder for the OpenAI text-embedding-3-small model\n",
    "enc = tiktoken.encoding_for_model(\"text-embedding-3-small\")\n",
    "\n",
    "# Encode each text in documents and calculate the total tokens\n",
    "total_tokens = sum(len(enc.encode(text)) for text in documents)\n",
    "\n",
    "cost_per_1k_tokens = 0.00002\n",
    "\n",
    "# Display number of tokens and cost\n",
    "print('Total tokens:', total_tokens)\n",
    "print('Cost:', cost_per_1k_tokens * total_tokens/1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbe4fe4-5408-41b7-bfed-4a81db2c7f95",
   "metadata": {},
   "source": [
    "#### Adding data to the collection\n",
    "\n",
    "Time to add those Netflix films and TV shows to your collection! You've been provided with a list of document IDs and texts, stored in `ids` and `documents`, respectively, which have been extracted from `netflix_titles.csv` using the following code:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d84cec60-4603-4bb3-8a26-a1a1623ff7d4",
   "metadata": {},
   "source": [
    "ids = []\n",
    "documents = []\n",
    "\n",
    "with open('netflix_titles.csv') as csvfile:\n",
    "  reader = csv.DictReader(csvfile)\n",
    "  for i, row in enumerate(reader):\n",
    "    ids.append(row['show_id'])\n",
    "    text = f\"Title: {row['title']} ({row['type']})\\nDescription: {row['description']}\\nCategories: {row['listed_in']}\"\n",
    "    documents.append(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651e1827-e37e-4fa8-94a6-3935019165f5",
   "metadata": {},
   "source": [
    "As an example of what information will be embedded, here's the first document from documents:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "253fe0d4-0002-4b76-970e-9efeaf70b3c3",
   "metadata": {},
   "source": [
    "Title: Dick Johnson Is Dead (Movie)\n",
    "Description: As her father nears the end of his life, filmmaker Kirsten Johnson stages his death in inventive and comical ways to help them both face the inevitable.\n",
    "Categories: Documentaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90070c3-f079-4f39-a5e2-c5cf87c99c5c",
   "metadata": {},
   "source": [
    "All of the necessary functions and packages have been imported, and a persistent client has been created and assigned to client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a570b1c-50d6-4753-8a09-9388e8f81ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [(\"s\"+str(i)) for i in range(1,1001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9679064-1ae5-41bc-955a-5a1291f6f518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate the netflix_titles collection\n",
    "collection = client.create_collection(\n",
    "  name=\"netflix_titles\",\n",
    "  embedding_function=OpenAIEmbeddingFunction(model_name=\"text-embedding-3-small\", api_key=api_key),\n",
    "  get_or_create=True  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1eb476-ec95-4c15-b5ae-540aa8805fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the documents and IDs to the collection\n",
    "collection.add(ids=ids, documents=documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d8c81b-38ea-48e1-a3cc-8a58c7db7c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the collection size and first ten items\n",
    "print(f\"No. of documents: {collection.count()}\")\n",
    "print(f\"First ten documents: {collection.peek}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391d44dd-b622-4595-a03c-2cb3e7fa1154",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.peek().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118a867b-3f10-4b3c-803c-132de8ef51ce",
   "metadata": {},
   "source": [
    "### Section 3.3 - Querying the Netflix collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566c42c4-b7f0-46f0-829c-89e7501676c9",
   "metadata": {},
   "source": [
    "#### Querying the Netflix collection\n",
    "Now that you've created and populated the `netflix_titles` collection, it's time to query it!\n",
    "\n",
    "As a first trial, you'll use it to provide recommendations for films and TV shows about dogs to one of your colleagues who loves dogs!\n",
    "\n",
    "The `netflix_titles` collection is still available to use, and `OpenAIEmbeddingFunction()` has been imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e41c25f-f6f9-45ff-9195-d779a1f0bc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the netflix_titles collection\n",
    "collection = client.get_collection(\n",
    "  name=\"netflix_titles\",\n",
    "  embedding_function=OpenAIEmbeddingFunction(model_name=\"text-embedding-3-small\", api_key=api_key)\n",
    ")\n",
    "\n",
    "# Query the collection for \"films about dogs\"\n",
    "result = collection.query(\n",
    "  query_texts=[\"films about cats\"],\n",
    "  n_results=3\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff6cdb6-52f5-4959-9d2b-9251443d326d",
   "metadata": {},
   "source": [
    "#### Updating and deleting items from a collection\n",
    "Just because the documents have been stored away in a vector database, that doesn't mean that you can't make changes to add to the collection or update existing items.\n",
    "\n",
    "In this exercise, you've been provided with two new Netflix titles stored in `new_data`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e812ecf9-0c11-4d53-90c0-27fc383b71dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = [\n",
    "    {\"id\": \"s1001\", \"document\": \"Title: Cats & Dogs (Movie)\\nDescription: A look at the top-secret, high-tech espionage war going on between cats and dogs, of which their human owners are blissfully unaware.\"},\n",
    "    {\"id\": \"s6884\", \"document\": 'Title: Goosebumps 2: Haunted Halloween (Movie)\\nDescription: Three teens spend their Halloween trying to stop a magical book, which brings characters from the \"Goosebumps\" novels to life.\\nCategories: Children & Family Movies, Comedies'}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29c9049-0e10-4193-98b3-4ce376f9ceed",
   "metadata": {},
   "source": [
    "You'll either add or update these IDs in the database depending on whether they're already present in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845de03b-cfd6-4d2f-9483-f592adead250",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_collection(\n",
    "  name=\"netflix_titles\",\n",
    "  embedding_function=OpenAIEmbeddingFunction(model_name=\"text-embedding-3-small\", \n",
    "                                             api_key=api_key)\n",
    ")\n",
    "\n",
    "# Update or add the new documents\n",
    "collection.upsert(\n",
    "    ids=[rec['id'] for rec in new_data],\n",
    "    documents=[rec['document'] for rec in new_data]\n",
    ")\n",
    "\n",
    "# Delete the item with ID \"s95\"\n",
    "collection.delete(ids=[\"s95\"])\n",
    "\n",
    "result = collection.query(\n",
    "    query_texts=[\"films about dogs\"],\n",
    "    n_results=3\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b37128-d292-4788-93be-0bf1c5dc00af",
   "metadata": {},
   "source": [
    "### Section 3.4 - Multiple queries and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b996932c-9af5-4c17-be88-5f4877436ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "ids = []\n",
    "metadata = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7469e3a-8785-46a4-8519-6618f095f27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./raw_data/netflix_titles_1000.csv') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for i, row in enumerate(reader):\n",
    "        ids.append(\"s\"+str(i))\n",
    "        metadata.append({\n",
    "            \"type\": row['type'],\n",
    "            \"rating\": row[\"rating\"],\n",
    "            \"release_year\": int(row[\"release_year\"])})\n",
    "        print(row)\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa74975-2e9d-4512-8fb7-230c3bc75505",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.update(ids=ids, metadatas=metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6375f2-0126-4730-9756-0e93ad1b54c6",
   "metadata": {},
   "source": [
    "#### Querying with multiple texts\n",
    "In many cases, you'll want to query the vector database using multiple query texts. Recall that these query texts are embedded using the same embedding function as when the documents were added.\n",
    "\n",
    "In this exercise, you'll use the documents from two IDs in the `netflix_titles` collection to query the rest of the collection, returning the most similar results as recommendations.\n",
    "\n",
    "The `netflix_titles` collection is still available to use, and `OpenAIEmbeddingFunction()` has been imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc279098-3ca5-4c2a-adcb-e09e232561d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_collection(\n",
    "  name=\"netflix_titles\",\n",
    "  embedding_function=OpenAIEmbeddingFunction(model_name=\"text-embedding-3-small\", api_key=api_key)\n",
    ")\n",
    "\n",
    "reference_ids = ['s999', 's1000']\n",
    "\n",
    "# Retrieve the documents for the reference_ids\n",
    "reference_texts = collection.get(ids=reference_ids)['documents']\n",
    "\n",
    "# Query using reference_texts\n",
    "result = collection.query(\n",
    "  query_texts=reference_texts,\n",
    "  n_results=3\n",
    ")\n",
    "\n",
    "print(result['documents'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d88f60e-0cfd-4381-8eb5-3b64124600a5",
   "metadata": {},
   "source": [
    "#### Filtering using metadata\n",
    "Having metadata available to use in the database can unlock the ability to more easily filter results based on additional conditions. Imagine that the film recommendations you've be creating could access the user's set preferences and use those to further filter the results.\n",
    "\n",
    "In this exercise, you'll be using additional metadata to filter your Netflix film recommendations. The netflix_titles collection has been updated to add metadatas to each `title`, including the `'rating'`, the age rating given to the title, and `'release_year'`, the year the title was initially released.\n",
    "\n",
    "Here's a preview of an updated item:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c7e5a4e-4e17-4d43-9136-b692356bed71",
   "metadata": {},
   "source": [
    "{'ids': ['s999'],\n",
    " 'embeddings': None,\n",
    " 'metadatas': [{'rating': 'TV-14', 'release_year': 2021}],\n",
    " 'documents': ['Title: Searching For Sheela (Movie)\\nDescription: Journalists and fans await Ma Anand Sheela as the infamous former Rajneesh commune’s spokesperson returns to India after decades for an interview tour.\\nCategories: Documentaries, International Movies'],\n",
    " 'uris': None,\n",
    " 'data': None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955db121-6c95-4bc0-97e2-b3d53e875623",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_collection(\n",
    "  name=\"netflix_titles\",\n",
    "  embedding_function=OpenAIEmbeddingFunction(model_name=\"text-embedding-3-small\", api_key=api_key)\n",
    ")\n",
    "\n",
    "reference_texts = [\"children's story about a car\", \"lions\"]\n",
    "\n",
    "# Query two results using reference_texts\n",
    "result = collection.query(\n",
    "  query_texts=reference_texts,\n",
    "  n_results=2,\n",
    "  # Filter for titles with a G rating released before 2019\n",
    "  where={\n",
    "    \"$and\": [\n",
    "        {\"rating\": \n",
    "        \t{\"$eq\": \"G\"}\n",
    "        },\n",
    "        {\"release_year\": \n",
    "         \t{\"$lt\": 2019}\n",
    "        }\n",
    "    ]\n",
    "  }\n",
    ")\n",
    "\n",
    "print(result['documents'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d03f350-309e-4e28-81f9-32ce42b074ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
