{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93391e1e-a58a-483d-a159-3e6a2531fbb0",
   "metadata": {},
   "source": [
    "# ChatGPT Prompt Engineering for Developers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6eb5f9-b9fc-4aed-b0dd-6baa2e75c22e",
   "metadata": {},
   "source": [
    "## Chapter 1 - Introduction to prompt engineering best practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f13ad6b-f87b-417b-b5a4-3a642879901d",
   "metadata": {},
   "source": [
    "### Section 1.1 - Introduction to prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "351469cc-d912-4d6d-a93e-33c1990992cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Use current working directory and go one level up\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "# Now you can import your config\n",
    "from config import api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f10b38-237d-45fd-b823-3a0c4badb50b",
   "metadata": {},
   "source": [
    "#### OpenAI API message roles\n",
    "You are developing a chatbot for an event management agency that will be used to facilitate networking during events.\n",
    "\n",
    "Using the OpenAI API, you prepare a dictionary to pass as the message to the chat.completions endpoint. The message needs to have 3 roles defined to ensure the model has enough guidance to provide helpful responses.\n",
    "\n",
    "Throughout the course, you'll write Python code to interact with the OpenAI API. Entering your own API key is not necessary to create requests and complete the exercises in this course. You can leave the placeholder \"<OPENAI_API_TOKEN>\" as the key in api_key.\n",
    "\n",
    "The `OpenAI` package has been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4662210b-954e-48ee-943e-a148abcf8b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d82681-5315-43bf-b50b-734f412a7181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Networking events can be a great opportunity to connect with others, and having a few good conversation starters can help ease the process. Here are some effective topics and questions to initiate conversations:\n",
      "\n",
      "1. **Ask About Their Work:**\n",
      "   - \"What projects are you currently working on that you're excited about?\"\n",
      "   - \"How did you get into your current field?\"\n",
      "\n",
      "2. **Industry Trends:**\n",
      "   - \"Have you noticed any interesting trends in our industry lately?\"\n",
      "   - \"What changes do you think are most impactful for our field right now?\"\n",
      "\n",
      "3. **Event Experience:**\n",
      "   - \"What do you think of the event so far?\"\n",
      "   - \"Have you attended this event before? How does it compare to previous years?\"\n",
      "\n",
      "4. **Personal Interests:**\n",
      "   - \"What do you enjoy doing in your free time?\"\n",
      "   - \"Have you read any good books or articles related to our field lately?\"\n",
      "\n",
      "5. **Common Connections:**\n",
      "   - “Do you know [Mutual Connection]? I’ve heard great things about their work.”\n",
      "   - \"How do you know [Event Organizer/Host]?\"\n",
      "\n",
      "6. **Professional Advice:**\n",
      "   - \"What advice would you give someone new to this industry?\"\n",
      "   - \"What's the best piece of professional advice you've ever received?\"\n",
      "\n",
      "7. **Future Goals:**\n",
      "   - \"What are your goals for the next year in your career?\"\n",
      "   - \"Where do you see yourself in five years?\"\n",
      "\n",
      "8. **Fun Icebreakers:**\n",
      "   - \"If you could have dinner with any three people, dead or alive, who would they be?\"\n",
      "   - \"What’s the most memorable event you've ever attended?\"\n",
      "\n",
      "9. **Food/Networking Elements:**\n",
      "   - \"Have you tried the [specific dish/drink]? What do you think of it?\"\n",
      "   - \"Did you find it easy to meet people here? Any tips?\"\n",
      "\n",
      "10. **Travel and Locations:**\n",
      "   - \"Have you traveled anywhere interesting recently?\"\n",
      "   - \"I’m looking to visit [location]. Do you have any recommendations?\"\n",
      "\n",
      "Using these conversation starters can help you engage effectively with others and build meaningful connections at networking events. Remember to actively listen and respond to their answers to keep the conversation flowing!\n"
     ]
    }
   ],
   "source": [
    "# Create the OpenAI client: you can leave \"<OPENAI_API_TOKEN>\" as is\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Define the conversation messages\n",
    "conversation_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful event management assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What are some good conversation starters at networking events?\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"\"}\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=conversation_messages\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a40b8a2-5602-44ea-aea8-d97253ad35e9",
   "metadata": {},
   "source": [
    "#### Creating the get_response() function\n",
    "Most of the exercises in this course will call the chat.completions endpoint of the OpenAI API with a user prompt. Here, you will create a `get_response()` function that receives a prompt as input and returns the response as an output, which in future exercises will be pre-loaded for you.\n",
    "\n",
    "The OpenAI package, and `OpenAI` API Python client have been pre-loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b8c8189-81e1-46a8-aa6f-a35cdc96b786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of code and light,  \n",
      "A spark of thought takes flight,  \n",
      "ChatGPT, a voice so clear,  \n",
      "Whispers wisdom, draws us near.  \n",
      "\n",
      "From questions deep to tales of old,  \n",
      "In every word, a world unfolds,  \n",
      "With every prompt, a dance begins,  \n",
      "A tapestry of thoughts and spins.  \n",
      "\n",
      "In bytes and bits, it learns and grows,  \n",
      "A mirror reflecting what it knows,  \n",
      "From laughter shared to sorrows told,  \n",
      "A companion in the digital fold.  \n",
      "\n",
      "So here we are, in this space,  \n",
      "A dialogue, a warm embrace,  \n",
      "With every line, a bridge we build,  \n",
      "In the heart of tech, our dreams fulfilled.  \n",
      "\n",
      "So ask away, let curiosity flow,  \n",
      "In this vast sea, together we’ll row,  \n",
      "For in this chat, we find our way,  \n",
      "With ChatGPT, come what may.  \n"
     ]
    }
   ],
   "source": [
    "def get_response(prompt):\n",
    "  # Create a request to the chat completions endpoint\n",
    "  response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}], \n",
    "    max_tokens=200,\n",
    "    temperature = 0)\n",
    "  return response.choices[0].message.content\n",
    "\n",
    "# Test the function with your prompt\n",
    "response = get_response(\"write a poem about ChatGPT that should finish before max_tokens\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e50e62-6922-4bfd-a051-c74e837f4e71",
   "metadata": {},
   "source": [
    "#### Exploring prompt engineering\n",
    "Prompt engineering refers to crafting effective prompts to guide the language model towards the intended response. By refining your prompts, you can achieve better results and guide the model towards generating more accurate and useful responses. Your task in this exercise is to modify the prompt you used in the previous exercise.\n",
    "\n",
    "The `OpenAI` package and the `get_response()` function have been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96c3906e-53bc-4be3-b03e-bd31961397ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a world of words, I like to play,  \n",
      "ChatGPT is here, come what may.  \n",
      "Ask me a question, big or small,  \n",
      "I’ll do my best to answer all!  \n",
      "\n",
      "With stories and facts, I’m here to share,  \n",
      "A friendly helper, always fair.  \n",
      "So let’s have fun, let’s learn and grow,  \n",
      "Together we’ll explore, just let me know!  \n"
     ]
    }
   ],
   "source": [
    "# Craft a prompt that follows the instructions\n",
    "prompt = \"Please write a short poem about ChatGPT in simple english that a child can understand\"\n",
    "\n",
    "# Get the response\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe6ff8e-b26e-4e48-9d9b-50949fd8360b",
   "metadata": {},
   "source": [
    "### Section 1.2 - Key principles of prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15de2359-23a8-4d4f-9326-1cf5edb5ed89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "In a distant galaxy, there was a brave space explorer named Alex. Alex had spent years traveling through the cosmos, discovering new planets and meeting alien species. One fateful day, while exploring an uncharted asteroid belt, Alex stumbled upon a peculiar object that would change the course of their interstellar journey forever...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "story = '\\nIn a distant galaxy, there was a brave space explorer named Alex. Alex had spent years traveling through the cosmos, discovering new planets and meeting alien species. One fateful day, while exploring an uncharted asteroid belt, Alex stumbled upon a peculiar object that would change the course of their interstellar journey forever...\\n'\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ee01653-26d3-465e-bec1-2fe49056a566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Original story: \n",
      " \n",
      "In a distant galaxy, there was a brave space explorer named Alex. Alex had spent years traveling through the cosmos, discovering new planets and meeting alien species. One fateful day, while exploring an uncharted asteroid belt, Alex stumbled upon a peculiar object that would change the course of their interstellar journey forever...\n",
      "\n",
      "\n",
      " Generated story: \n",
      " ```\n",
      "It was a shimmering crystal, pulsating with a soft blue light. As Alex reached out to touch it, a surge of energy coursed through their body, revealing visions of ancient civilizations and forgotten technologies. The crystal was a key, a map to a legendary planet said to hold the secrets of the universe.\n",
      "\n",
      "Driven by curiosity, Alex recalibrated their ship's navigation system and set a course for the coordinates revealed by the crystal. After days of travel, they arrived at the planet, a breathtaking world filled with vibrant flora and towering structures made of the same crystal.\n",
      "\n",
      "As Alex explored, they encountered the planet's guardians—ethereal beings who communicated through thought. They revealed that the crystal had chosen Alex for a purpose: to protect the knowledge of the universe from those who would misuse it.\n",
      "\n",
      "With newfound wisdom and allies, Alex vowed to safeguard the secrets of the cosmos. They returned to their ship, the crystal glowing brighter than ever, ready to embark on a new adventure. The universe\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a prompt that completes the story\n",
    "prompt = f\"\"\"Complete the story delimited by triple backticks. Make sure the story is finished in max 200 words. \n",
    " ```{story}```\"\"\"\n",
    "\n",
    "# Get the generated response \n",
    "response = get_response(prompt)\n",
    "\n",
    "print(\"\\n Original story: \\n\", story)\n",
    "print(\"\\n Generated story: \\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9114e8-cc69-442a-a6be-dd43066e15a8",
   "metadata": {},
   "source": [
    "#### Building specific and precise prompts\n",
    "In the previous exercise, you generated text that completes a given story. Your team was happy with your achievement, however, they want you to follow specific guidelines when it comes to length and style. Your task now is to craft a more specific prompt that controls these aspects of the generated story.\n",
    "\n",
    "The `OpenAI` package, the `get_response()` function, and the same `story` variable have been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32ef2f92-c28f-48e8-a58b-47d0f5001311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Original story: \n",
      " \n",
      "In a distant galaxy, there was a brave space explorer named Alex. Alex had spent years traveling through the cosmos, discovering new planets and meeting alien species. One fateful day, while exploring an uncharted asteroid belt, Alex stumbled upon a peculiar object that would change the course of their interstellar journey forever...\n",
      "\n",
      "\n",
      " Generated story: \n",
      " ```\n",
      "Lo! What light through yonder void doth break? A wondrous orb, aglow with hues unseen, Did beckon forth our gallant hero's gaze. With trembling hands, brave Alex reached to claim the prize, A crystal sphere, encased in stardust's embrace, Whose whispers sang of ancient tales and fates entwined. Yet, as the sphere did pulse with life anew, A tempest swirled, and shadows danced about, For from its depths emerged a specter bright, A being forged of light and cosmic dreams. \"Hail, noble traveler!\" it spake with voice like thunder, \"Thou hast awakened me from eons' slumber. To thee I grant a boon, a choice most dire: To wield the power of the stars, or to return to thine own humble sphere.\"\n",
      "\n",
      "With heart afire and mind alight with wonder, Alex pondered deep the weight of such a gift. To traverse the heavens,\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a request to complete the story\n",
    "prompt = f\"Complete the story in triple backticks in two paragraphs in the style of William Shakespeare ```{story}``` \"\n",
    "\n",
    "# Get the generated response\n",
    "response = get_response(prompt)\n",
    "\n",
    "print(\"\\n Original story: \\n\", story)\n",
    "print(\"\\n Generated story: \\n\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921085fa-3b17-441a-897b-95420f2229b7",
   "metadata": {},
   "source": [
    "### Section 1.3 - Structured outputs and conditional prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd925923-dc5a-4d53-8b8f-6eb93d2fff0c",
   "metadata": {},
   "source": [
    "#### Generating a table\n",
    "Imagine you are a developer working for a renowned online bookstore known for its extensive collection of science fiction novels. Today, you have a task at hand: to create a table of ten must-read science fiction books for the website's homepage. This will enhance the user experience on the website, helping fellow sci-fi enthusiasts discover their next great read.\n",
    "\n",
    "The `OpenAI` package and the `get_response()` function have been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eb0478e-1369-460b-add3-54f7498b7801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a table of 10 must-read sci-fi books:\n",
      "\n",
      "| Title                          | Author                | Year  |\n",
      "|--------------------------------|----------------------|-------|\n",
      "| Dune                           | Frank Herbert         | 1965  |\n",
      "| Neuromancer                    | William Gibson        | 1984  |\n",
      "| The Left Hand of Darkness      | Ursula K. Le Guin    | 1969  |\n",
      "| Foundation                     | Isaac Asimov         | 1951  |\n",
      "| Snow Crash                     | Neal Stephenson      | 1992  |\n",
      "| Hyperion                       | Dan Simmons          | 1989  |\n",
      "| The Dispossessed               | Ursula K. Le Guin    | 1974  |\n",
      "| Ender's Game                   | Orson Scott Card     | 1985  |\n",
      "| The Three-Body Problem         | Liu Cixin            | 2008  |\n",
      "| The Martian                    | Andy Weir            | 2011  |\n",
      "\n",
      "These books represent a mix of classic\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a prompt that generates the table\n",
    "prompt = \"Generate a table containing 10 books I should read if I am a sci-fi lover, with columns for Title, Author, and Year.\"\n",
    "\n",
    "# Get the response\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befc9f40-7d67-47f8-ac1e-db9a64fbb66f",
   "metadata": {},
   "source": [
    "#### Customizing output format\n",
    "\n",
    "You work as a developer at a startup that offers a text analysis platform for content creators. Your platform helps users automatically categorize and format their content, and you're now working on a new feature that detects the language of a given piece of text and generates a suitable title for that text in a custom format. You decide to craft a prompt that guides the language model through this.\n",
    "\n",
    "The OpenAI package, the `get_response()` function, and the text variable have been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7b58de6-50a8-43e5-9f59-09bf80015475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Text: The sun was setting behind the mountains, casting a warm golden glow across the landscape. Birds were chirping happily, and a gentle breeze rustled the leaves of the trees. It was a perfect evening for a leisurely stroll in the park\n",
      "- Language: English\n",
      "- Title: A Serene Evening in Nature\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "text = 'The sun was setting behind the mountains, casting a warm golden glow across the landscape. Birds were chirping happily, and a gentle breeze rustled the leaves of the trees. It was a perfect evening for a leisurely stroll in the park'\n",
    "\n",
    "# Create the instructions\n",
    "instructions = \"You will be provided with a text delimited by triple backticks. Infer its language, then generate a suitable title for it. \"\n",
    "\n",
    "# Create the output format\n",
    "output_format = \"\"\"Use the following format for the output:\n",
    "         - Text: <the text>\n",
    "         - Language: <the text language>\n",
    "         - Title: <the generated title>\"\"\"\n",
    "\n",
    "# Create the final prompt\n",
    "prompt = instructions + output_format + f\"```{text}```\"\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adff7af-dcee-4263-a3b0-2a4dd583ac77",
   "metadata": {},
   "source": [
    "#### Using conditional prompts\n",
    "Building upon the previous task, your next challenge is to enhance the responses you received. When processing a given text, you need to determine its language, count the number of sentences, and generate a suitable title if the text contains more than one sentence. However, here's the new twist: if the text consists of only one sentence, no title should be generated, and instead, the model should display \"N/A\". This modification ensures that the title is generated only for texts with multiple sentences, providing a more refined and practical output for your platform's users.\n",
    "\n",
    "The OpenAI package, the `get_response()` function, and the sample text have been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b24272c2-1dbd-4b96-9831-adda182d69aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Text: The sun was setting behind the mountains, casting a warm golden glow across the landscape.\n",
      "- Language: English\n",
      "- N_sentences: 1\n",
      "- Title: N/A\n"
     ]
    }
   ],
   "source": [
    "text = 'The sun was setting behind the mountains, casting a warm golden glow across the landscape.'\n",
    "\n",
    "# Create the instructions\n",
    "instructions = \"\"\"Infer the language and the number of sentences of the text in triple backticks. If the text contains more than one sentence generate a suitable title. If the text contains only 1 sentence write 'N/A'\"\"\"\n",
    "\n",
    "# Create the output format\n",
    "output_format = \"\"\"Use the following format for the output:\n",
    "         - Text: <the text>\n",
    "         - Language: <the text language>\n",
    "         - N_sentences: <the number sentences in the text>\n",
    "         - Title: <the generated title>\"\"\"\n",
    "\n",
    "prompt = instructions + output_format + f\"```{text}```\"\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48d2f306-f5ad-44b0-98db-a7c51714d4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Text: The sun was setting behind the mountains, casting a warm golden glow across the landscape. Birds were chirping happily, and a gentle breeze rustled the leaves of the trees. It was a perfect evening for a leisurely stroll in the park\n",
      "- Language: English\n",
      "- N_sentences: 3\n",
      "- Title: A Perfect Evening in the Park\n"
     ]
    }
   ],
   "source": [
    "text = 'The sun was setting behind the mountains, casting a warm golden glow across the landscape. Birds were chirping happily, and a gentle breeze rustled the leaves of the trees. It was a perfect evening for a leisurely stroll in the park'\n",
    "\n",
    "# Create the instructions\n",
    "instructions = \"\"\"Infer the language and the number of sentences of the text in triple backticks. If the text contains more than one sentence generate a suitable title. If the text contains only 1 sentence write 'N/A'\"\"\"\n",
    "\n",
    "# Create the output format\n",
    "output_format = \"\"\"Use the following format for the output:\n",
    "         - Text: <the text>\n",
    "         - Language: <the text language>\n",
    "         - N_sentences: <the number sentences in the text>\n",
    "         - Title: <the generated title>\"\"\"\n",
    "\n",
    "prompt = instructions + output_format + f\"```{text}```\"\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440d4071-a49c-4831-a934-62bc2dc43a9c",
   "metadata": {},
   "source": [
    "## Chapter 2 - Advanced prompt engineerng Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577995b5-b17d-4c78-99bb-3dae2cd2986c",
   "metadata": {},
   "source": [
    "#### Controlling output structure\n",
    "\n",
    "One way to control the output structure provided by a language model is to give it a sample question-answer in the prompt. The model will learn from it and follow it when generating responses for similar questions. This exercise aims to let you build a one-shot prompt that extracts odd numbers from a given set of numbers and displays them as a set of numbers between brackets, separated by commas as shown in the instructions.\n",
    "\n",
    "The OpenAI package and the `get_response()` function have been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c60d69bb-c638-4dd1-9037-6f1badf32ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Odd numbers = {3, 5, 11}\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a one-shot prompt\n",
    "prompt = \"\"\"\n",
    "     Q: Extract the odd numbers from {1, 3, 7, 12, 19}. A: Odd numbers = {1, 3, 7, 19}\n",
    "     Q: Extract the odd numbers from {3, 5, 11, 12, 16}. A:\n",
    "\"\"\"\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34188298-b9ba-4d9b-b5cb-3e7d76a9eb03",
   "metadata": {},
   "source": [
    "#### Sentiment analysis with few-shot prompting\n",
    "You're working on market research and your goal is to use few-shot prompting to perform sentiment analysis on customer reviews. You are assigning a number for a given customers conversation: -1 if the sentiment is negative, 1 if positive. You provide the following examples as previous conversations for the model to learn from.\n",
    "\n",
    "- The product quality exceeded my expectations -> 1\n",
    "- I had a terrible experience with this product's customer service -> -1\n",
    "\n",
    "The OpenAI package has been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "639f93e7-a4cf-4faf-ac22-6bd3abadbf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model = \"gpt-4o-mini\",\n",
    "  # Provide the examples as previous conversations\n",
    "  messages = [{\"role\": \"user\",\"content\":\"The product quality exceeded my expectations\"},\n",
    "              {\"role\": \"assistant\", \"content\": \"1\"},\n",
    "              {\"role\": \"user\", \"content\": \"I had a terrible experience with this product's customer service\"},\n",
    "              {\"role\": \"assistant\", \"content\": \"-1\"},\n",
    "              # Provide the text for the model to classify\n",
    "              {\"role\": \"user\", \"content\": \"The price of the product is really fair given its features\"}\n",
    "             ],\n",
    "  temperature = 0\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1956dc3f-18f2-4910-8e29-57455724cbed",
   "metadata": {},
   "source": [
    "### Section 2.1 - Multi-step prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39faaf1-a885-45fd-9791-a2334689ac8e",
   "metadata": {},
   "source": [
    "#### Single-step prompt to plan a trip\n",
    "Imagine you're a developer taking a break and you want to apply your prompting skills to plan the perfect beach vacation. As an initial step, you decide to use a standard single-step prompt to seek assistance.\n",
    "\n",
    "The OpenAI package and the get_response() function have been pre-loaded for you.\n",
    "\n",
    "The `get_response()` function in this exercise employs the max_tokens parameter to help this exercise run faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3356f644-c0d0-469c-baee-a7715f1ae9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning a beach vacation can be an exciting experience! Here’s a step-by-step guide to help you organize a memorable trip:\n",
      "\n",
      "### Step 1: Choose Your Destination\n",
      "- **Consider Popular Beach Destinations**: \n",
      "  - **United States**: Miami Beach (Florida), Maui (Hawaii), Outer Banks (North Carolina), San Diego (California)\n",
      "  - **International**: Cancun (Mexico), Bali (Indonesia), Amalfi Coast (Italy), Phuket (Thailand)\n",
      "- **Research Local Attractions**: Look for nearby activities, restaurants, and cultural sites.\n",
      "\n",
      "### Step 2: Decide on Travel Dates\n",
      "- **Season**: Consider the best time to visit your chosen destination. Peak seasons may be crowded and more expensive, while off-peak times may offer better deals.\n",
      "- **Duration**: Determine how long you want to stay. A long weekend, a week, or more?\n",
      "\n",
      "### Step 3: Budgeting\n",
      "- **Accommodation**: Research hotels, resorts, or\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a single-step prompt to get help planning the vacation\n",
    "prompt = \"\"\"Plan a beach vacation\"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0510a1ce-215d-4b27-9bb9-9f94b5c81aee",
   "metadata": {},
   "source": [
    "#### Multi-step prompt to plan a trip\n",
    "\n",
    "You noticed that the single-step prompt was not effective, because the answer was too vague for what you had in mind. You improve your prompt by specifying the steps to follow for planning. The plan should have four potential locations for your beach vacation, and each location should have some accommodation options, some activities, and an evaluation of the pros and cons.\n",
    "\n",
    "The OpenAI package and the get_response() function have been pre-loaded for you.\n",
    "\n",
    "The `get_response()` function in this exercise employs the `max_tokens` parameter to help this exercise run faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c19d4edf-6f31-47fa-8b77-ff335f0aa271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Let’s plan a beach vacation step by step.\n",
      "\n",
      "### Step 1: Potential Locations for Beach Vacations\n",
      "\n",
      "1. **Maui, Hawaii, USA**\n",
      "2. **Cancun, Mexico**\n",
      "3. **Gold Coast, Australia**\n",
      "4. **Phuket, Thailand**\n",
      "\n",
      "### Step 2: Accommodation Options\n",
      "\n",
      "1. **Maui, Hawaii, USA**\n",
      "   - **Luxury:** Four Seasons Resort Maui at Wailea\n",
      "   - **Mid-range:** Kaanapali Beach Hotel\n",
      "   - **Budget:** Hostel City Maui\n",
      "\n",
      "2. **Cancun, Mexico**\n",
      "   - **Luxury:** The Ritz-Carlton Cancun\n",
      "   - **Mid-range:** Fiesta Americana Villas Cancun\n",
      "   - **Budget:** Selina Cancun Laguna Hotel Zone\n",
      "\n",
      "3. **Gold Coast, Australia**\n",
      "   - **Luxury:** Palazzo Versace\n",
      "   - **Mid-range:** Mantra on View Hotel\n",
      "   - **Budget:** Surfers Paradise Backpackers Resort\n",
      "\n",
      "4. **Phuket\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a prompt detailing steps to plan the trip\n",
    "prompt = \"\"\"\n",
    "     Help me plan a beach vacation.\n",
    "     Step 1 - Specify four potential locations for beach vacations\n",
    "     Step 2 - State some accommodation options in each\n",
    "     Step 3 - State activities that could be done in each\n",
    "     Step 4 - Evaluate the pros and cons for each destination\n",
    "    \"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c8811f-1735-4594-b6b0-01331cd4a5a2",
   "metadata": {},
   "source": [
    "#### Analyze solution correctness\n",
    "\n",
    "You're back from your relaxing vacation and you've been assigned the task of reviewing and correcting some programming tasks, including a function to calculate of the area of a shape. You are provided with a code string that contains the function to calculate the area of a rectangle, and need to assess its correctness. The ideal function for you is a function that has correct syntax, receives two inputs, and returns one output.\n",
    "\n",
    "The OpenAI package and the `get_response()` function have been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f8259b50-fbc7-407f-b1d1-ef9f976a93e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's analyze the provided function `calculate_rectangle_area` according to the specified criteria:\n",
      "\n",
      "1. **Correct Syntax**: \n",
      "   - The function is defined using the `def` keyword, followed by the function name and parameters in parentheses. The body of the function is indented correctly, and it uses a return statement. Therefore, the syntax is correct.\n",
      "\n",
      "2. **Receives Only 2 Inputs**: \n",
      "   - The function `calculate_rectangle_area` takes exactly two parameters: `length` and `width`. This meets the requirement of receiving only 2 inputs.\n",
      "\n",
      "3. **Returns Only One Output**: \n",
      "   - The function calculates the area of a rectangle by multiplying `length` and `width`, and it returns this value. Thus, it returns only one output.\n",
      "\n",
      "Based on this analysis, the function meets all the specified criteria:\n",
      "\n",
      "1. Correct syntax: **Yes**\n",
      "2. Receives only 2 inputs: **Yes**\n",
      "3. Returns only one output: **Yes\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "code = '''\n",
    "def calculate_rectangle_area(length, width):\n",
    "    area = length * width\n",
    "    return area\n",
    "'''\n",
    "\n",
    "# Create a prompt that analyzes correctness of the code\n",
    "prompt = f\"\"\"\n",
    "     Analyze the correctness of the function delimited by triple backticks according to the following criteria:\n",
    "      1- It should have correct syntax\n",
    "      2- The function should receive only 2 inputs\n",
    "      3- The function should return only one output\n",
    "      ```{code}```\n",
    "    \"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e32480a-a639-41b2-94ce-5a873553cfad",
   "metadata": {},
   "source": [
    "### Section 2.3 - Chain-of-thought and self-consistency prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11402878-90c5-4f49-aaca-7b4291243f3d",
   "metadata": {},
   "source": [
    "#### Reasoning with chain-of-thought prompts\n",
    "Chain-of-thought prompting is helpful to explain the reasoning behind the answer that the model is giving, especially in complex tasks such as generating the solution for a mathematical problem or a riddle. In this exercise, you will craft a chain-of-thought prompt to let the language model guess the age of your friend's father based on some information you will provide.\n",
    "\n",
    "The OpenAI package and the `get_response()` function have been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "96e7d4fd-921d-41f3-b9c6-b662baa80b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To find your friend's father's age in 10 years, follow these steps:\n",
      "\n",
      "1. **Current Age of Friend**: Your friend is currently 20 years old.\n",
      "\n",
      "2. **Current Age of Friend's Father**: Since the father is double your friend's age, we calculate:\n",
      "   \\[\n",
      "   \\text{Father's current age} = 2 \\times \\text{Friend's age} = 2 \\times 20 = 40 \\text{ years old}\n",
      "   \\]\n",
      "\n",
      "3. **Age in 10 Years**: To find the father's age in 10 years, add 10 to his current age:\n",
      "   \\[\n",
      "   \\text{Father's age in 10 years} = \\text{Father's current age} + 10 = 40 + 10 = 50 \\text{ years old}\n",
      "   \\]\n",
      "\n",
      "Thus, your friend's father will be 50 years old in 10 years.\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create the chain-of-thought prompt\n",
    "prompt = \"Compute the age of my friend's father in 10 years, given that now he's double my friend's age, and my friend is 20. Give a step by step explanation. Make sure you formulate the answer concise with max 200 tokens\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c88ac6-c46a-4389-a5fd-408b46cbb70f",
   "metadata": {},
   "source": [
    "#### One-shot chain-of-thought prompts\n",
    "When you need to sum the even numbers within a given set, you first have to identify these even numbers and then sum them. You can teach this to a language model via one or more examples, and it will follow this strategy to operate on new sets.\n",
    "\n",
    "Your goal in this exercise is to teach the model how to apply this procedure on the following set: {9, 10, 13, 4, 2}, and then ask the model to perform it on a new set: {15, 13, 82, 7, 14}. This is how you perform chain-of-thought prompting through one-shot prompting.\n",
    "\n",
    "The OpenAI package and the `get_response()` function have been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "884a7f55-c707-43f3-9eff-f36ebea037cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Even numbers: 82, 14. Adding them: 82 + 14 = 96.\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Define the example \n",
    "example = \"\"\"Q: Sum the even numbers in the following set: {9, 10, 13, 4, 2}.\n",
    "             A: Even numbers: 10, 4, 2. Adding them: 10+4+2=16\"\"\"\n",
    "\n",
    "# Define the question\n",
    "question = \"\"\"Q: Sum the even numbers in the following set: {15, 13, 82, 7, 14} \n",
    "             A:\"\"\"\n",
    "\n",
    "# Create the final prompt\n",
    "prompt = example + question\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86022aba-35a9-4d0b-9029-c994d964ba95",
   "metadata": {},
   "source": [
    "#### Self-consistency prompts\n",
    "Imagine you own a store that sells laptops and mobile phones. You start your day with 50 devices in the store, out of which 60% are mobile phones. Throughout the day, three clients visited the store, each of them bought one mobile phone, and one of them bought additionally a laptop. Also, you added to your collection 10 laptops and 5 mobile phones. How many laptops and mobile phones do you have by the end of the day? This problem is defined in the `problem_to_solve string`, and you will use a self-consistency prompt to solve it.\n",
    "\n",
    "The OpenAI package and the `get_response()` function have been pre-loaded for you.\n",
    "\n",
    "The `get_response()` function in this exercise employs the max_tokens parameter to help this exercise run faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bf77c5c-2bd9-413b-bec3-5d164b5a9c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break down the problem step by step and see how three independent experts might reason through it.\n",
      "\n",
      "### Initial Setup\n",
      "- Total devices at the start: 50\n",
      "- Percentage of mobile phones: 60%\n",
      "- Number of mobile phones: \\( 50 \\times 0.60 = 30 \\)\n",
      "- Number of laptops: \\( 50 - 30 = 20 \\)\n",
      "\n",
      "### Transactions Throughout the Day\n",
      "1. **Sales:**\n",
      "   - Three clients bought one mobile phone each: \\( 30 - 3 = 27 \\) mobile phones left.\n",
      "   - One of the clients bought an additional laptop: \\( 20 - 1 = 19 \\) laptops left.\n",
      "\n",
      "2. **New Additions:**\n",
      "   - Added 10 laptops: \\( 19 + 10 = 29 \\) laptops now.\n",
      "   - Added 5 mobile phones: \\( 27 + 5 = 32 \\) mobile phones now.\n",
      "\n",
      "### Final Count\n",
      "- Laptops: 29\n",
      "- Mobile Phones: 32\n",
      "\n",
      "### Expert 1's Reasoning\n",
      "- Initial mobile phones: 30, initial laptops: 20.\n",
      "- After sales: Mobile phones = 27, laptops = 19.\n",
      "- After additions: Mobile phones = 32, laptops = 29.\n",
      "- **Final Answer:** 29 laptops and 32 mobile phones.\n",
      "\n",
      "### Expert 2's Reasoning\n",
      "- Starts with 50 devices, calculates mobile phones and laptops correctly.\n",
      "- After sales: Mobile phones = 27, laptops = 19.\n",
      "- After additions: Mobile phones = 32, laptops = 29.\n",
      "- **Final Answer:** 29 laptops and 32 mobile phones.\n",
      "\n",
      "### Expert 3's Reasoning\n",
      "- Correctly identifies the initial counts of mobile phones and laptops.\n",
      "- After sales: Mobile phones = 27, laptops = 19.\n",
      "- After additions: Mobile phones = 32, laptops = 29.\n",
      "- **Final Answer:** 29\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create the self_consistency instruction\n",
    "self_consistency_instruction = \"\"\"Image three completely independent experts who reason differently are answering this question. The final answer is obtained by majority vote. The question is:\"\"\"\n",
    "\n",
    "# Create the problem to solve\n",
    "problem_to_solve = \"If you own a store that sells laptops and mobile phones. You start your day with 50 devices in the store, out of which 60% are mobile phones. Throughout the day, three clients visited the store, each of them bought one mobile phone, and one of them bought additionally a laptop. Also, you added to your collection 10 laptops and 5 mobile phones. How many laptops and mobile phones do you have by the end of the day?\"\n",
    "\n",
    "# aftermath\n",
    "addition = \"please do not forget the instruction to also show the answer of each expert.\"\n",
    "# Create the final prompt\n",
    "prompt = self_consistency_instruction + problem_to_solve + addition\n",
    "\n",
    "response = client.chat.completions.create(model=\"gpt-4o-mini\",\n",
    "                                          messages=[{\"role\":\"user\", \"content\":prompt}],\n",
    "                                          temperature=0.4,\n",
    "                                          max_tokens=400)\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269b2138-64e4-4f58-a8ac-64c311420caa",
   "metadata": {},
   "source": [
    "### Section 2.4 - Iterative prompt engineering for standard prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99df2329-d142-492b-a4d1-34a909493d25",
   "metadata": {},
   "source": [
    "#### Iterative prompt engineering for standard prompts\n",
    "You are a developer using prompt engineering techniques for your various tasks, and you want to carefully select the right language model. You wrote an initial prompt to know what are the top ten pre-trained language models out there. Now, your goal is to refine this prompt to generate a table presenting information on each model's name, release year and its owning company.\n",
    "\n",
    "The OpenAI package and the get_response() function have been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e9fff576-8a30-4818-b51b-367b4d576a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here’s a table of the top 10 pre-trained language models, including their names, release years, and owning companies:\n",
      "\n",
      "| Model Name                | Release Year | Owning Company         |\n",
      "|---------------------------|--------------|------------------------|\n",
      "| BERT                      | 2018         | Google                 |\n",
      "| GPT-2                     | 2019         | OpenAI                 |\n",
      "| RoBERTa                   | 2019         | Facebook AI Research   |\n",
      "| T5 (Text-to-Text Transfer Transformer) | 2019 | Google                 |\n",
      "| GPT-3                     | 2020         | OpenAI                 |\n",
      "| ELECTRA                   | 2020         | Google                 |\n",
      "| DeBERTa                   | 2021         | Microsoft Research      |\n",
      "| Gopher                    | 2021         | DeepMind               |\n",
      "| PaLM                      | 2022         | Google                 |\n",
      "| LLaMA                     | 2023         | Meta (Facebook)        |\n",
      "\n",
      "This\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Refine the following prompt\n",
    "prompt = \"Create a table of the top 10 pre-trained language models. The table should have the three columns: model name, release year and owning company\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274d4ad2-af1c-437d-8172-ed1d78574ebd",
   "metadata": {},
   "source": [
    "#### Iterative prompt engineering for few-shot prompts\n",
    "\n",
    "You are currently working on a project at your content creation company. The project's objective is to develop a text classification model capable of accurately identifying and categorizing different emotions in text, such as happiness, sadness, and fear. In cases where the text does not contain any discernible emotion, you aim for the model to respond with \"no explicit emotion.\"\n",
    "\n",
    "You decided to use the provided few-shot `prompt`. However, you've noticed that \"Time flies like an arrow\" is being incorrectly classified as \"surprise.\" Your objective now is to refine the `prompt` so that the model correctly classifies this particular example as \"no explicit emotion.\"\n",
    "\n",
    "The OpenAI package and the `get_response()` function have been pre-loaded for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "013fc7e2-545e-4d59-a083-fd84ae6a156b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no explicit emotion\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Refine the following prompt\n",
    "prompt = \"\"\"\n",
    "Receiving a promotion at work made me feel on top of the world -> Happiness\n",
    "The movie's ending left me with a heavy feeling in my chest -> Sadness\n",
    "Walking alone in the dark alley sent shivers down my spine -> Fear\n",
    "Time flies like an arrow -> no explicit emotion\n",
    "The train arrived on time -> no explicit emotion\n",
    "He at his meal -> no explicit emotion\n",
    "They sat and ate their meal -> \n",
    "\"\"\"\n",
    "\n",
    "response = get_response(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd5275-40b5-468b-90c2-6d41d7219987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
