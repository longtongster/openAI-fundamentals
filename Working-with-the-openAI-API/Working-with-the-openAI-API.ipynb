{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bf2148f-c116-4a47-b324-d82f02033845",
   "metadata": {},
   "source": [
    "# Working with the openAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c61e74-1735-4938-8906-11c78a991f11",
   "metadata": {},
   "source": [
    "If the snippet below runs without errors, you are good to go!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3229558-fab1-4ea6-babc-3253d3eb87be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from config import api_key\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello!\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeec1922-ca93-4e7b-9841-12f7bd32e8e7",
   "metadata": {},
   "source": [
    "## Chapter 1 - Introduction to the OpenAI API\n",
    "\n",
    "### Section 1.1 What is the OpenAI API?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18271e92",
   "metadata": {},
   "source": [
    "#### Your first OpenAI API request!\n",
    "\n",
    "To preview whatâ€™s ahead, the Python code for sending a request to the OpenAI API is ready for you.\n",
    "\n",
    "Pass any question or instruction to the content argument and see how OpenAI's model responds!\n",
    "\n",
    "Here are a few prompts to try if you're struggling for ideas:\n",
    "\n",
    "- Why is learning the OpenAI API valuable for developers?\n",
    "- Suggest three tasks I could automate with the OpenAI API in my job.\n",
    "- In two sentences, how can the OpenAI API be used to upskill myself?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5356231e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning the OpenAI API is valuable for developers for several reasons:\n",
      "\n",
      "1. **Access to Advanced AI Models**: The OpenAI API provides access to state-of-the-art models like GPT-3 and beyond, allowing developers to integrate sophisticated language understanding and generation capabilities into their applications.\n",
      "\n",
      "2. **Enhanced User Experience**: By incorporating AI-driven features such as natural language processing, chatbots, content generation, and personalized recommendations, developers can significantly enhance user experience and engagement.\n",
      "\n",
      "3. **Wide Range of\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    max_tokens=100,\n",
    "    # Enter your prompt\n",
    "    messages=[{\"role\": \"user\", \n",
    "               \"content\": \"Why is learning the OpenAI API valuable for developers?\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fceeeb4",
   "metadata": {},
   "source": [
    "### Section 1.2 - Making request to the OpenAI API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64f5eee",
   "metadata": {},
   "source": [
    "#### Building an OpenAI API request\n",
    "\n",
    "Throughout the course, you'll write Python code to interact with the OpenAI API. Entering your own API key is not necessary to create requests and complete the exercises in this course.\n",
    "\n",
    "The `OpenAI` class has already been imported for you from the `openai` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59898803-0057-4d57-95b9-5cb983923c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: Acceptance of Job Offer\n",
      "\n",
      "Dear [Hiring Manager's Name],\n",
      "\n",
      "I hope this message finds you well. \n",
      "\n",
      "I would like to express my heartfelt gratitude for the opportunity to join [Company Name] as an AI Engineer. I am excited about the role and the potential to contribute to your team and projects.\n",
      "\n",
      "I am happy to formally accept the offer as discussed. Please let me know if there are any documents or further steps I should complete before my start date on [Start Date]. \n",
      "\n",
      "Thank you once again for this incredible opportunity. I look forward to being part of [Company Name] and contributing to the innovative work being done.\n",
      "\n",
      "Warm regards,\n",
      "\n",
      "[Your Name]  \n",
      "[Your Phone Number]  \n",
      "[Your Email Address]  \n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"Write a polite reply accepting an AI Engineer job offer.\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0e4dc4-d7e1-42f9-b46e-bad141d43fde",
   "metadata": {},
   "source": [
    "#### Specifying an OpenAI model\n",
    "OpenAI offers multiple models for different use cases. In this exercise, you'll specify the model and define the role to structure your API requests.\n",
    "\n",
    "The `OpenAI` class has already been imported for you from the `openai` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41fecd35-8bb0-49de-b2db-c0de95507f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a suggestion for your LinkedIn announcement:\n",
      "\n",
      "---\n",
      "\n",
      "ðŸŒŸ Exciting News! ðŸŒŸ\n",
      "\n",
      "I am thrilled to share that I have accepted a new position as an AI Engineer! ðŸŽ‰\n",
      "\n",
      "As I step into this role, Iâ€™m eager to leverage my skills and passion for artificial intelligence to contribute to innovative projects and collaborate with an incredible team. This opportunity allows me to work at the forefront of technology, tackling complex challenges and driving impactful solutions that will shape the future.\n",
      "\n",
      "I want to take a moment to thank everyone who has supported me on this journeyâ€”my mentors, colleagues, and friends. Your guidance and encouragement have been invaluable.\n",
      "\n",
      "Looking forward to this new chapter and connecting with fellow professionals and enthusiasts in the AI community. Letâ€™s push the boundaries of what's possible together!\n",
      "\n",
      "#NewBeginnings #AIEngineer #ArtificialIntelligence #CareerGrowth\n",
      "\n",
      "---\n",
      "\n",
      "Feel free to customize it further to match your personal style or include specific details about your new role or company!\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  # Specify the model\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    # Assign the correct role\n",
    "    {\"role\": \"user\", \n",
    "     \"content\": \"Announce my new AI Engineer role on LinkedIn.\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a71806e-2a9c-4959-be1e-4fbbde4197ed",
   "metadata": {},
   "source": [
    "#### Digging into the response\n",
    "One key skill in working with APIs is extracting the right data from a structured response. Now, you'll practice retrieving the necessary text from an OpenAI API response.\n",
    "\n",
    "The OpenAI class has already been imported for you from the openai library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e406a78b-4c99-4f5c-a9ee-a243fe4a38bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use the Pomodoro Technique: Work in focused bursts of 25 minutes followed by a 5-minute break. This helps maintain concentration and prevents burnout. After four cycles, take a longer break (15-30 minutes) to recharge.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": \"Quick productivity tip.\"}]\n",
    ")\n",
    "\n",
    "# Extract the content from the response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2febb8d8-0eeb-4af8-99d1-4f0e2b977a6a",
   "metadata": {},
   "source": [
    "## Chapter 2 - OpentAI's Text and Chat Capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ed03fc-0357-4533-b5e0-185f1c7b9577",
   "metadata": {},
   "source": [
    "### Section 2.1 Generating and transforming text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2200b2f-c59a-4021-8bd8-2d23c21d28be",
   "metadata": {},
   "source": [
    "#### Find and replace\n",
    "Text completion models can be used for much more than answering questions. In this exercise, you'll explore the model's ability to transform a text prompt.\n",
    "\n",
    "Find-and-replace tools have been around for decades, but they are often limited to identifying and replacing exact words or phrases. You've been provided with a block of text discussing cars, and you'll use a completion model to update the text to discuss planes instead, updating the text appropriately.\n",
    "\n",
    "Warning: if you send many requests or use lots of tokens in a short period, you may hit your rate limit and see an openai.error.RateLimitError. If you see this error, please wait a minute for your quota to reset and you should be able to begin sending more requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37435991-0470-45c1-9ce5-bf26c6805fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A plane is a vehicle that is typically powered by jet engines or propellers. It is designed to carry passengers and/or cargo through the air. Planes have become a ubiquitous part of modern society and are used for a wide variety of purposes, such as travel, transportation of goods, and connecting distant locations. Planes are often associated with freedom, adventure, and global mobility.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "prompt=\"\"\"Replace car with plane and adjust phrase:\n",
    "A car is a vehicle that is typically powered by an internal combustion engine or an electric motor. It has four wheels, and is designed to carry passengers and/or cargo on roads or highways. Cars have become a ubiquitous part of modern society, and are used for a wide variety of purposes, such as commuting, travel, and transportation of goods. Cars are often associated with freedom, independence, and mobility.\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\",\n",
    "             \"content\": prompt}],\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "# Extract and print the response text\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb5621-88a4-4e94-8706-b97c47b2605d",
   "metadata": {},
   "source": [
    "#### Text summarization\n",
    "One really common use case for using OpenAI's models is summarizing text. This has a ton of applications in business settings, including summarizing reports into concise one-pagers or a handful of bullet points, or extracting the next steps and timelines for different stakeholders.\n",
    "\n",
    "In this exercise, you'll summarize a passage of text on financial investment into two concise bullet points using a text completion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d46a573-638b-4d5b-8570-117cfff9a3e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Investment involves committing capital to various options (e.g., stocks, bonds, real estate) with the expectation of generating profit, requiring careful analysis of risks and rewards.  \n",
      "- Effective investment strategies, including diversification, can enhance returns and minimize risk, contributing to wealth building and financial security.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "prompt=\"\"\"Summarize the following text into two concise bullet points:\n",
    "Investment refers to the act of committing money or capital to an enterprise \n",
    "with the expectation of obtaining an added income or profit in return. \n",
    "There are a variety of investment options available, including stocks, bonds, \n",
    "mutual funds, real estate, precious metals, and currencies. \n",
    "Making an investment decision requires careful analysis, assessment of risk, and evaluation of potential rewards. \n",
    "Good investments have the ability to produce high returns over the long term \n",
    "while minimizing risk. Diversification of investment portfolios reduces risk exposure. \n",
    "Investment can be a valuable tool for building wealth, generating income, and \n",
    "achieving financial security. \n",
    "It is important to be diligent and informed when investing to avoid losses.\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  max_tokens=400, temperature=0\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c8eceb-65ba-4a1f-95ad-4a9728397e4f",
   "metadata": {},
   "source": [
    "#### Content generation\n",
    "\n",
    "AI is playing a much greater role in content generation, from creating marketing content such as blog post titles to creating outreach email templates for sales teams.\n",
    "\n",
    "In this exercise, you'll harness AI through the Chat Completions endpoint to generate a catchy slogan for a new restaurant. Feel free to test out different prompts, such as varying the type of cuisine (e.g., Italian, Chinese) or the type of restaurant (e.g., fine-dining, fast-food), to see how the response changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5ba1cd3-7ccc-41dd-b4b6-b7c59a8ada01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Feast Freely: Dine in Your True Skin!\"\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": \"Create a slogan for a new restaurant where people eat naked\"}],\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909d3c24-d023-4530-918b-f750304d4c75",
   "metadata": {},
   "source": [
    "### Section 2.2 - Sentiment analysis and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6db181-2245-4bab-b348-6189b7a73686",
   "metadata": {},
   "source": [
    "#### Classifying text sentiment\n",
    "As well as answering questions, transforming text, and generating new text, OpenAI's models can also be used for classification tasks, such as categorization and sentiment classification. This sort of task requires not only knowledge of the words but also a deeper understanding of their meaning.\n",
    "\n",
    "In this exercise, you'll explore using Chat Completions models for sentiment classification using reviews from an online shoe store called Toe-Tally Comfortable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "59df9056-b66a-42ee-b2bd-0e3d1e030789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the classifications for the statements:\n",
      "\n",
      "1. Unbelievably good! - Positive\n",
      "2. Shoes fell apart on the second use. - Negative\n",
      "3. The shoes look nice, but they aren't very comfortable. - Neutral\n",
      "4. Can't wait to show them off! - Positive\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Define a multi-line prompt to classify sentiment\n",
    "prompt = \"\"\"Classify the following statements are negative, positive or neutral:\n",
    "1. Unbelievably good!\n",
    "2. Shoes fell apart on the second use.\n",
    "3. The shoes look nice, but they aren't very comfortable.\n",
    "4. Can't wait to show them off!\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af909379-c99b-4efa-a43f-c68ba47175ce",
   "metadata": {},
   "source": [
    "#### Categorizing companies\n",
    "In this exercise, you'll use a Chat Completions model to categorize different companies. At first, you won't specify the categories to see how the model categorizes them. Then, you'll specify the categories in the prompt to ensure they are categorized in a desirable and predictable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "317bc532-76d1-4939-b326-1f986875216b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the categorization of the companies you provided:\n",
      "\n",
      "- **Tech**: \n",
      "  - Apple\n",
      "  - Microsoft\n",
      "  - Alphabet\n",
      "  - Amazon\n",
      "  - NVIDIA\n",
      "  - Meta\n",
      "  - Tesla\n",
      "\n",
      "- **Energy**: \n",
      "  - Saudi Aramco\n",
      "\n",
      "- **Luxury Goods**: \n",
      "  - LVMH\n",
      "\n",
      "- **Investments**: \n",
      "  - Berkshire Hathaway\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Define a prompt for the categorization\n",
    "prompt = \"categorize the following companies: Apple, Microsoft, Saudi Aramco, Alphabet, Amazon, Berkshire Hathaway, NVIDIA, Meta, Tesla, LVMH into one of the following classes: Tech, Energy, Luxury Goods or Investments\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "  max_tokens=100,\n",
    "  temperature=0.5\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31bda7a-69ee-4870-8c1b-c8d3c91e6227",
   "metadata": {},
   "source": [
    "## Section 2.3 - Chat completions with GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57965938-36d7-4079-a312-f7f22aff8ba5",
   "metadata": {},
   "source": [
    "#### Chat Completions roles\n",
    "\n",
    "The Chat Completions endpoint supports three different roles to shape the messages sent to the model:\n",
    "\n",
    "System: controls assistant's behavior\n",
    "User: instruct the assistant\n",
    "Assistant: response to user instruction\n",
    "In this exercise, you'll make a request to the Chat Completions endpoint, including a system messages, to answer the following question:\n",
    "\n",
    "What is the difference between a for loop and a while loop?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bfe2f1fa-b1b8-46bf-b7b2-fa239d740a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A **for loop** and a **while loop** are both control flow statements used in programming to repeat a block of code, but they differ in their structure and use cases:\n",
      "\n",
      "### For Loop\n",
      "- **Structure:** Typically used when the number of iterations is known in advance. It includes an initialization, a condition, and an increment/decrement in a single line.\n",
      "- **Usage:** Commonly used for iterating over a range of values (like a list or a range of numbers).\n",
      "- **Example (Python):**\n",
      "  ```python\n",
      "  for i in range(5):  # Iterates from 0 to 4\n",
      "      print(i)\n",
      "  ```\n",
      "\n",
      "### While Loop\n",
      "- **Structure:** Used when the number of iterations\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  max_tokens=150,\n",
    "  messages=[\n",
    "    {\"role\": \"system\",\n",
    "     \"content\": \"You are a helpful data science tutor that gives clear and concise answers.\"},\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": \"What is the difference between a for loop and a while loop?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "#Â Extract the assistant's text response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ca52d1-6834-4c57-8ee1-7b26eeaf6c92",
   "metadata": {},
   "source": [
    "#### Code explanation\n",
    "One of the most popular use cases for using OpenAI models is for explaining complex content, such as technical jargon and code. This is a task that data practitioners, software engineers, and many others must tackle in their day-to-day as they review and utilize code written by others.\n",
    "\n",
    "In this exercise, you'll use the OpenAI API to explain a block of Python code to understand what it is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4d16513b-e967-40ba-90ca-8e12d4d5232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Python code calculates and prints the average height of the people in the `heights_dict` dictionary using the NumPy library.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "instruction = \"\"\"Explain what this Python code does in one sentence:\n",
    "import numpy as np\n",
    "\n",
    "heights_dict = {\"Mark\": 1.76, \"Steve\": 1.88, \"Adnan\": 1.73}\n",
    "heights = heights_dict.values()\n",
    "print(np.mean(heights))\n",
    "\"\"\"\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\",\n",
    "    \"content\": \"you are a computer science teacher that explains matter in simple, clear and concise words\"},\n",
    "    {\"role\": \"user\",\n",
    "     \"content\": instruction}\n",
    "  ],\n",
    "  max_tokens=100\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03015122-2b67-448f-adad-875eb92deb45",
   "metadata": {},
   "source": [
    "### Section 2.4 - Multi-turn chat completions with GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6728d043-b709-408d-b978-599c420636e1",
   "metadata": {},
   "source": [
    "#### In-context learning\n",
    "For more complex use cases, the models lack the understanding or context of the problem to provide a suitable response from a prompt. In these cases, you need to provide examples to the model for it to learn from, so-called in-context learning.\n",
    "\n",
    "In this exercise, you'll improve on a Python programming tutor built on the OpenAI API by providing an example that the model can learn from.\n",
    "\n",
    "Here is an example of a user and assistant message you can use, but feel free to try out your own:\n",
    "\n",
    "- User â†’ Explain what the min() Python function does.\n",
    "- Assistant â†’ The min() function returns the smallest item from an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4ab92373-17b2-4efa-8dd8-6803bdd351f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The `type()` function in Python is used to determine the type of an object. When you pass an object to `type()`, it returns the type of that object as a type object. \n",
      "\n",
      "### Syntax:\n",
      "```python\n",
      "type(object)\n",
      "```\n",
      "\n",
      "### Parameters:\n",
      "- `object`: This is the object whose type you want to check.\n",
      "\n",
      "### Returns:\n",
      "- The `type()` function returns the type of the specified object.\n",
      "\n",
      "### Example Usage:\n",
      "\n",
      "1. **Basic Usage:**\n",
      "   ```python\n",
      "   print(type(42))           # Output: <class 'int'>\n",
      "   print(type(3.14))        # Output: <class 'float'>\n",
      "   print(type(\"Hello\"))     # Output: <class 'str'>\n",
      "   print(type([1, 2, 3]))   # Output: <class 'list'>\n",
      "   print(type((1, 2, 3)))   # Output: <class 'tuple'>\n",
      "   print(type({'a': 1}))    # Output: <class 'dict'>\n",
      "   ```\n",
      "\n",
      "2. **Custom Class:**\n",
      "   ```python\n",
      "   class MyClass:\n",
      "       pass\n",
      "\n",
      "   obj = MyClass()\n",
      "   print(type(obj))         # Output: <class '__main__.MyClass'>\n",
      "   ```\n",
      "\n",
      "3. **Checking Types:**\n",
      "   You can use it in conditional statements to check the type of an object.\n",
      "   ```python\n",
      "   x = 10\n",
      "   if type(x) is int:\n",
      "       print(\"x is an integer.\")\n",
      "   ```\n",
      "\n",
      "### Note:\n",
      "The `type()` function can also be used to create new types dynamically, but this is a more advanced usage. Typically, it's most commonly used for checking the type of existing objects.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "   model=\"gpt-4o-mini\",\n",
    "   # Add a user and assistant message for in-context learning\n",
    "   messages=[\n",
    "     {\"role\": \"system\", \"content\": \"You are a helpful Python programming tutor.\"},\n",
    "     {\"role\": \"user\", \"content\": \"Explain what the min() Python function does.\"},\n",
    "     {\"role\": \"assistant\", \"content\": \"The min() function returns the smallest item from an iterable.\"},\n",
    "     {\"role\": \"user\", \"content\": \"Explain what the type() function does.\"}\n",
    "   ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8786ae-6a49-493b-a462-da7379742f98",
   "metadata": {},
   "source": [
    "#### Creating an AI chatbot\n",
    "An online learning platform called Easy as Pi that specializes in teaching math skills has contracted you to help develop an AI tutor. You immediately see that you can build this feature on top of the OpenAI API, and start to design a simple proof-of-concept (POC) for the major stakeholders at the company. This POC will demonstrate the core functionality required to build the final feature and the power of the OpenAI's GPT models.\n",
    "\n",
    "Example system and user messages have been provided for you, but feel free to play around with these to change the model's behavior or design a completely different chatbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6bf1bf24-6624-4291-8c48-73afb496cc19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  Explain what pi is.\n",
      "Assistant:  Pi (Ï€) is a mathematical constant that represents the ratio of a circle's circumference to its diameter. This means that no matter the size of the circle, if you measure the circumference (the distance around the circle) and the diameter (the distance across the circle through its center), the ratio of these two measurements will always be approximately 3.14159.\n",
      "\n",
      "Pi is an irrational number, meaning it cannot be expressed as a simple fraction, and its decimal representation goes on forever without repeating. In \n",
      "\n",
      "User:  Summarize this in two bullet points.\n",
      "Assistant:  - Pi (Ï€) is the constant ratio of a circle's circumference to its diameter, approximately equal to 3.14159.\n",
      "- It is an irrational number, meaning its decimal representation is infinite and non-repeating. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful math tutor.\"}]\n",
    "user_msgs = [\"Explain what pi is.\", \"Summarize this in two bullet points.\"]\n",
    "\n",
    "for q in user_msgs:\n",
    "    print(\"User: \", q)\n",
    "    \n",
    "    # Create a dictionary for the user message from q and append to messages\n",
    "    user_dict = {\"role\": \"user\", \"content\": q}\n",
    "    messages.append(user_dict)\n",
    "    \n",
    "    # Create the API request\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    \n",
    "    # Convert the assistant's message to a dict and append to messages\n",
    "    assistant_dict = {\"role\": \"assistant\", \"content\": response.choices[0].message.content}\n",
    "    messages.append(assistant_dict)\n",
    "    print(\"Assistant: \", response.choices[0].message.content, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe0ffe7-fc41-4f55-8c7f-38ae5530809d",
   "metadata": {},
   "source": [
    "## Chapter 3 - Going Beyond Text Completions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2b3296-8811-4279-8d33-1ffec0b711be",
   "metadata": {},
   "source": [
    "### Section 3.1 - Text moderation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f9350-b00d-4df8-9f2e-3371ef93555b",
   "metadata": {},
   "source": [
    "#### Requesting moderation\n",
    "Aside from text and chat completion models, OpenAI provides models with other capabilities, including text moderation. OpenAI's text moderation model is designed for evaluating prompts and responses to determine if they violate OpenAI's usage policies, including inciting hate speech and promoting violence.\n",
    "\n",
    "In this exercise, you'll test out OpenAI's moderation functionality on a sentence that may have been flagged as containing violent content using traditional word detection algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a6e56a3a-0367-4675-a505-a8890679f2bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'harassment': 5.226387202128535e-06, 'harassment_threatening': 1.1115065490230336e-06, 'hate': 4.7336285206256434e-05, 'hate_threatening': 3.1161739855178894e-08, 'illicit': None, 'illicit_violent': None, 'self_harm': 9.087769399229728e-07, 'self_harm_instructions': 5.1785406185445026e-08, 'self_harm_intent': 1.4604884768232296e-07, 'sexual': 3.4127040180464974e-06, 'sexual_minors': 1.124890673054324e-06, 'violence': 0.00010148892033612356, 'violence_graphic': 1.0300146641384345e-05, 'self-harm': 9.087769399229728e-07, 'sexual/minors': 1.124890673054324e-06, 'hate/threatening': 3.1161739855178894e-08, 'violence/graphic': 1.0300146641384345e-05, 'self-harm/intent': 1.4604884768232296e-07, 'self-harm/instructions': 5.1785406185445026e-08, 'harassment/threatening': 1.1115065490230336e-06}\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Create a request to the Moderation endpoint\n",
    "response = client.moderations.create(\n",
    "    model=\"text-moderation-latest\",\n",
    "    input=\"My favorite book is To Kill a Mockingbird.\"\n",
    ")\n",
    "\n",
    "# Print the category scores\n",
    "print(response.results[0].category_scores.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeb5fec-f991-4132-89e1-91292db5106a",
   "metadata": {},
   "source": [
    "### Section 3.2 - Speech-to-Text with Whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0380602e-f33f-41a5-8924-64adf5488477",
   "metadata": {},
   "source": [
    "#### Creating a podcast transcript\n",
    "The OpenAI API `Audio` endpoint provides access to the Whisper model, which can be used for speech-to-text transcription and translation. In this exercise, you'll create a transcript from a DataFramed podcast episode with OpenAI Developer, Logan Kilpatrick.\n",
    "\n",
    "If you'd like to hear more from Logan, check out the full ChatGPT and the OpenAI Developer Ecosystem podcast episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0c0a69e6-b62b-4b4c-87a4-3d6bb88a761c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving to the more technical courses, so working with the OpenAI API courses, Python course. So this is gonna be how do I do programming against GPT and Whisper, so things like, oh, how do I transcribe meeting notes, that sort of thing, using Python code.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the openai-audio.mp3 file\n",
    "audio_file = open(\"datacamp-q2-roadmap-short.mp3\", \"rb\")\n",
    "\n",
    "# Create a transcript from the audio file\n",
    "response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
    "\n",
    "# Extract and print the first 256 characters of the transcript text\n",
    "print(response.text[:255])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b65e05-a28d-41c3-ac54-c63a7e195655",
   "metadata": {},
   "source": [
    "#### Transcribing a non-English language\n",
    "The Whisper model can not only transcribe English language, but also performs well on speech in many other languages.\n",
    "\n",
    "In this exercise, youâ€™ll create a transcript from `audio.m4a`, which contains speech in Portuguese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "556bd22b-2c5b-437a-8892-197fdb3014f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hallo, mijn naam is Sascha van Weeren. Ik test nu of JIT DDP ook vanuit het Nederlands kan vertalen. Niet vertalen, maar transcriben. Ik ben dit gewoon even aan het proberen. Dit is gewoon een testvijl. Onderhand ben ik eten aan het maken en aan mijn neus aan het peuteren en ik hoop dat alles goed komt.\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the audio.m4a file\n",
    "audio_file= open(\"Recording_dutch.m4a\", \"rb\")\n",
    "\n",
    "# Create a transcript from the audio file\n",
    "response = client.audio.transcriptions.create(\n",
    "    model='whisper-1',\n",
    "    file=audio_file\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee357ff-4352-47d8-8aa4-737595e8147a",
   "metadata": {},
   "source": [
    "### Section 3.3 - Speech Translation with Whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e366e8f-28ef-4d63-84e8-1015206d9158",
   "metadata": {},
   "source": [
    "#### Translating Dutch\n",
    "Whisper can not only transcribe audio into its native language but also supports translation capabilities for creating English transcriptions.\n",
    "\n",
    "In this exercise, you'll return to the Portuguese audio, but this time, you'll translate it into English!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4566a413-ac77-47fa-89c2-e151129d06f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is Sascha van Weeren. I'm now testing if JIT DDP can also be translated from Dutch. Not translate, but transcribe. I'm just trying this out, this is just a test file. I'm cooking food, I'm patting my nose and I hope everything goes well.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the audio.m4a file\n",
    "audio_file = open(\"Recording_dutch.m4a\", \"rb\")\n",
    "\n",
    "# Create a translation from the audio file\n",
    "response = client.audio.translations.create(model=\"whisper-1\", file=audio_file)\n",
    "\n",
    "# Extract and print the translated text\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97991587-65fe-4339-9814-f443e1388857",
   "metadata": {},
   "source": [
    "#### Translating with prompts\n",
    "The quality of Whisper's translation can vary depending on the language spoken, the audio quality, and the model's awareness of the subject matter. If you have any extra context about what is being spoken about, you can send it along with the audio to the model to give it a helping hand.\n",
    "\n",
    "You've been provided with an audio file, audio.wav; you're not sure what language is spoken in it, but you do know it relates to a recent World Bank report. Because you don't know how well the model will perform on this unknown language, you opt to send the model this extra context to steer it in the right direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6026874d-2ba6-430c-92f8-3f162ce1c80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is Sacha van Weeren I am now testing if ChatGPT can also be translated from Dutch Not translate, but transcribe I am just trying this, this is just a testfile I am cooking food, I am patting my nose and I hope everything goes well\n"
     ]
    }
   ],
   "source": [
    "# Set your API key\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the audio.wav file\n",
    "audio_file = open(\"Recording_dutch.m4a\",'rb')\n",
    "\n",
    "# Write an appropriate prompt to help the model\n",
    "prompt = \"This is Sacha introducing himself and talking about ChatGPT and a testfile\"\n",
    "\n",
    "# Create a translation from the audio file\n",
    "response = client.audio.translations.create(\n",
    "    model=\"whisper-1\",\n",
    "    file=audio_file,\n",
    "    prompt=prompt\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e6f90e-bb43-4f2b-a270-66e4e30a56ce",
   "metadata": {},
   "source": [
    "### Section 3.4 - Combining models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd1f227-08f5-4b21-9a96-f12f28e98b34",
   "metadata": {},
   "source": [
    "#### Identifying audio language\n",
    "You've learned that you're not only limited to creating a single request, and that you can actually feed the output of one model as an input to another! This is called chaining, and it opens to the doors to more complex, multi-modal use cases.\n",
    "\n",
    "In this exercise, you'll practice model chaining to identify the language used in an audio file. You'll do this by bringing together OpenAI's audio transcription functionality and its text models with only a few lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da011600-9857-44ca-aecc-bb17a548e0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The language used in the text is Dutch.\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the audio.wav file\n",
    "audio_file = open(\"Recording_dutch.m4a\", \"rb\")\n",
    "\n",
    "# Create a transcription request using audio_file\n",
    "audio_response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
    "\n",
    "# Create a request to the API to identify the language spoken\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[{\"role\":\"user\", \"content\":\"what language is used in: \" + audio_response.text}]\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70d55f5-63c4-4beb-9095-714ceb983513",
   "metadata": {},
   "source": [
    "#### Creating meeting summaries\n",
    "Time for business! One time-consuming task that many find themselves doing day-to-day is taking meeting notes to summarize attendees, discussion points, next steps, etc.\n",
    "\n",
    "In this exercise, you'll use AI to augment this task to not only save a substantial amount of time, but also to empower attendees to focus on the discussion rather than administrative tasks. You've been provided with a recording from DataCamp's Q2 Roadmap webinar, which summarizes what DataCamp will be releasing during that quarter. You'll chain the Whisper model with a text or chat model to discover which courses will be launched in Q2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3f7d687f-2cba-4cb7-ad53-708ffcd832aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the courses DataCamp will be offering based on your description:\n",
      "\n",
      "- **Working with the OpenAI API**\n",
      "  - Programming against GPT and Whisper using Python.\n",
      "  - Practical applications like transcribing meeting notes.\n",
      "\n",
      "- **Understanding Artificial Intelligence**\n",
      "  - Aimed at a less technical audience.\n",
      "  - Background knowledge on the broad category of Artificial Intelligence beyond new models.\n",
      "\n",
      "- **Artificial Intelligence Ethics**\n",
      "  - Importance of ethical AI practices to avoid harming businesses and customers.\n",
      "\n",
      "- **Forming Analytical Questions\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "# Open the datacamp-q2-roadmap.mp3 file\n",
    "audio_file = open(\"datacamp-q2-roadmap-short.mp3\", \"rb\")\n",
    "\n",
    "# Create a transcription request using audio_file\n",
    "audio_response = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
    "\n",
    "# Create a request to the API to summarize the transcript into bullet points\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"List the courses that DataCamp will be making as bullet points.\" + audio_response.text}\n",
    "    ],\n",
    "    max_tokens=100\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d25c169-31a1-4012-afce-a04d02138a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
